{
    "python-for-data-ai": {
        "title": "Python for Data & AI Track — 2025 Edition",
        "description": "Build strong foundations in Python programming, data analysis, and visualization. Master NumPy, Pandas, and Matplotlib with real-world projects and hands-on experience.",
        "duration": "6 weeks (60 hours)",
        "level": "Starter",
        "mode": "Online/Offline",
        "price": "₹7,000",
        "originalPrice": "₹10,000",
        "rating": 4.7,
        "students": 324,
        "nextBatch": "September 1, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-blue-500 to-blue-600",
        "icon": "Brain",
        "image": "https://images.pexels.com/photos/1181472/pexels-photo-1181472.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python 3",
            "Pandas",
            "NumPy",
            "Matplotlib",
            "Seaborn",
            "Jupyter Notebook",
            "VS Code",
            "GitHub",
            "CSV/JSON/Excel"
        ],
        "mentor": {
            "name": "Rajesh Kumar",
            "role": "Senior Data Scientist",
            "company": "Hexaware Technologies",
            "image": "https://images.pexels.com/photos/774909/pexels-photo-774909.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "8+ years in data science and Python development"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Python Fundamentals",
                "duration": "10 hours",
                "topics": [
                    "Installing Python & Jupyter via Anaconda/Miniconda",
                    "Variables, data types (integers, floats, strings, booleans)",
                    "Input/Output operations and f-strings formatting",
                    "Operators: arithmetic, comparison, logical, membership",
                    "Basic problem-solving exercises",
                    "Temperature converter and interest calculator projects"
                ]
            },
            {
                "week": "2",
                "title": "Control Structures & Functions",
                "duration": "10 hours",
                "topics": [
                    "Conditional statements (if, elif, else) and nested conditions",
                    "Loops: for loops with range, while loops with break/continue",
                    "Defining functions with parameters and return values",
                    "Function scope (local vs global) and docstrings",
                    "Using Python packages (math, random) and pip install",
                    "FizzBuzz problem and number guessing game"
                ]
            },
            {
                "week": "3",
                "title": "Data Structures & File Handling",
                "duration": "10 hours",
                "topics": [
                    "Lists: creation, indexing, slicing, CRUD operations",
                    "Tuples, Sets, and Dictionaries with comprehensions",
                    "File I/O operations with context managers",
                    "Reading/Writing CSV and JSON files",
                    "Contact book app with file persistence",
                    "Data cleaning and filtering exercises"
                ]
            },
            {
                "week": "4",
                "title": "Data Analysis with Pandas & NumPy",
                "duration": "12 hours",
                "topics": [
                    "NumPy arrays, operations, and broadcasting",
                    "Pandas Series and DataFrames fundamentals",
                    "Data cleaning: handling missing data and duplicates",
                    "Boolean indexing, filtering, and sorting data",
                    "Basic statistics: mean, median, std, describe(), groupby",
                    "Merging datasets and aggregation operations"
                ]
            },
            {
                "week": "5",
                "title": "Data Visualization",
                "duration": "10 hours",
                "topics": [
                    "Matplotlib: line plots, bar charts, histograms, scatter plots",
                    "Chart customization: colors, styles, titles, labels, legends",
                    "Subplots and figure management",
                    "Seaborn: distplots, boxplots, pairplots, heatmaps",
                    "Correlation analysis and trend visualization",
                    "Creating PDF/HTML reports with visualizations"
                ]
            },
            {
                "week": "6",
                "title": "Final Project & Portfolio",
                "duration": "8 hours",
                "topics": [
                    "Project scoping and dataset selection",
                    "End-to-end data analysis workflow",
                    "Creating well-documented Jupyter notebooks",
                    "GitHub version control and portfolio building",
                    "Presentation skills and storytelling with data",
                    "Code quality best practices and documentation"
                ]
            }
        ],
        "projects": [
            {
                "title": "Bangalore Weather Analysis",
                "description": "Analyze temperature trends, seasonal patterns, and create time series visualizations using real weather data from Bangalore",
                "technologies": [
                    "Python",
                    "Pandas",
                    "Matplotlib",
                    "NumPy"
                ],
                "image": "https://images.pexels.com/photos/1118873/pexels-photo-1118873.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "E-Commerce Sales Dashboard",
                "description": "Build a comprehensive sales analysis dashboard identifying best/worst sellers, product categories, and revenue trends",
                "technologies": [
                    "Python",
                    "Pandas",
                    "Seaborn",
                    "Jupyter"
                ],
                "image": "https://images.pexels.com/photos/590020/pexels-photo-590020.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Student Performance Analytics",
                "description": "Analyze student performance data to identify pass/fail rates, subject comparisons, and academic trends",
                "technologies": [
                    "Python",
                    "Pandas",
                    "Matplotlib",
                    "NumPy"
                ],
                "image": "https://images.pexels.com/photos/301926/pexels-photo-301926.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Air Quality Analysis",
                "description": "Study Bangalore air quality trends, correlations with weather patterns, and create environmental insights dashboard",
                "technologies": [
                    "Python",
                    "Pandas",
                    "Seaborn",
                    "Matplotlib"
                ],
                "image": "https://images.pexels.com/photos/459728/pexels-photo-459728.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master Python fundamentals and programming best practices",
            "Gain proficiency in data manipulation with Pandas and NumPy",
            "Create compelling data visualizations with Matplotlib and Seaborn",
            "Develop skills in data cleaning, filtering, and statistical analysis",
            "Build a professional portfolio with real-world projects",
            "Learn version control with GitHub for code management",
            "Understand the complete data analysis workflow",
            "Prepare for advanced AI/ML and data engineering topics"
        ],
        "prerequisites": [
            "Basic computer literacy",
            "No prior programming experience required",
            "Willingness to learn and practice coding",
            "Access to computer with internet connection"
        ],
        "courseOutcomes": [
            "Solid Python foundation ready for advanced topics (AI, data engineering, web development)",
            "Portfolio projects with real datasets and analysis for resumes and interviews",
            "Presentation skills to communicate technical work clearly",
            "Confidence to build, debug, and share working code",
            "Understanding of data science fundamentals",
            "Preparation for data analyst and junior data scientist roles"
        ],
        "toolsAndResources": {
            "platform": "Jupyter Notebook (VS Code recommended)",
            "libraries": [
                "Python 3",
                "Pandas",
                "NumPy",
                "Matplotlib",
                "Seaborn"
            ],
            "dataSources": [
                "Kaggle",
                "Government of India portals",
                "GitHub"
            ],
            "versionControl": "GitHub for saving and sharing code",
            "assessment": [
                "Weekly assignments",
                "In-class coding labs",
                "Capstone project"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "Personal greeting program with user input",
                    "Simple and compound interest calculator",
                    "Temperature converter (Celsius ↔ Fahrenheit)"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "FizzBuzz problem implementation",
                    "Number guessing game using random module",
                    "Prime number checker function"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "User data storage in JSON format",
                    "CSV price calculator with file output",
                    "Duplicate removal using sets"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Dataset loading, cleaning, and filtering",
                    "Statistical analysis and grouping operations",
                    "Multi-dataset merging and aggregation"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Time series visualization of weather data",
                    "Product price distribution analysis",
                    "Correlation matrix and heatmap creation"
                ]
            }
        ],
        "assessmentCriteria": {
            "codeQuality": "Clean, efficient, and well-commented code",
            "analysis": "Thoughtful approach with correct methodologies",
            "visuals": "Clear, informative, and well-labeled charts",
            "communication": "Ability to explain findings in plain language"
        }
    },
    "data-engineering-foundations": {
        "title": "Data Engineering Foundations — 2025 Edition",
        "description": "Learn the basics of managing, processing, and storing large datasets using modern data engineering tools. Build scalable data pipelines and infrastructure for analytics, reporting, and ML.",
        "duration": "6 weeks (60 hours)",
        "level": "Starter",
        "mode": "Online/Offline",
        "price": "₹7,000",
        "originalPrice": "₹10,000",
        "rating": 4.6,
        "students": 278,
        "nextBatch": "September 1, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-green-500 to-green-600",
        "icon": "Database",
        "image": "https://images.pexels.com/photos/1181677/pexels-photo-1181677.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "SQL",
            "PostgreSQL",
            "Apache Airflow",
            "Apache Spark",
            "Pandas",
            "Google BigQuery",
            "AWS Redshift",
            "Azure Synapse"
        ],
        "mentor": {
            "name": "Priya Sharma",
            "role": "Data Engineering Lead",
            "company": "LTI Mindtree",
            "image": "https://images.pexels.com/photos/1239291/pexels-photo-1239291.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "10+ years in data engineering and big data systems"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Introduction to Data Engineering",
                "duration": "10 hours",
                "topics": [
                    "Role and responsibilities of a data engineer",
                    "Overview of data pipelines and architecture",
                    "ETL vs ELT concepts and when to use each",
                    "Modern data stack overview",
                    "Real-world data pipeline case studies",
                    "Designing ETL/ELT workflows for business scenarios"
                ]
            },
            {
                "week": "2",
                "title": "Data Storage & Databases",
                "duration": "10 hours",
                "topics": [
                    "Relational vs NoSQL databases comparison",
                    "PostgreSQL setup and configuration",
                    "SQL basics: SELECT, JOIN, GROUP BY operations",
                    "Database optimization and indexing strategies",
                    "Sample data import and query execution",
                    "Hands-on labs with real datasets"
                ]
            },
            {
                "week": "3",
                "title": "Data Processing with Python & Pandas",
                "duration": "10 hours",
                "topics": [
                    "Reading/writing CSV, JSON, and database data",
                    "Data cleaning and transformation techniques",
                    "Handling missing values, duplicates, and outliers",
                    "Data type conversions and validation",
                    "Merging and reshaping datasets",
                    "Python scripts for automated data processing"
                ]
            },
            {
                "week": "4",
                "title": "Workflow Automation with Apache Airflow",
                "duration": "10 hours",
                "topics": [
                    "Introduction to Apache Airflow architecture",
                    "DAGs (Directed Acyclic Graphs) and task dependencies",
                    "Scheduling data pipelines and monitoring",
                    "Error handling, retries, and alerts",
                    "Creating and deploying Airflow workflows",
                    "Best practices for production environments"
                ]
            },
            {
                "week": "5",
                "title": "Big Data Processing with Apache Spark",
                "duration": "10 hours",
                "topics": [
                    "Introduction to Apache Spark and distributed computing",
                    "RDDs, DataFrames, and Spark SQL",
                    "Processing large datasets efficiently",
                    "Performance tuning and optimization",
                    "Spark jobs on real datasets",
                    "Comparison with traditional data processing"
                ]
            },
            {
                "week": "6",
                "title": "Final Project & Cloud Deployment",
                "duration": "10 hours",
                "topics": [
                    "Building complete automated ETL pipeline",
                    "Cloud data warehouse deployment",
                    "End-to-end project implementation",
                    "Code documentation and best practices",
                    "Performance monitoring and optimization",
                    "Portfolio presentation and project demo"
                ]
            }
        ],
        "projects": [
            {
                "title": "Sales Data Pipeline for Analytics",
                "description": "Build an end-to-end automated ETL pipeline that ingests, transforms, and loads sales data into a cloud data warehouse with Airflow scheduling",
                "technologies": [
                    "Python",
                    "Apache Airflow",
                    "Apache Spark",
                    "PostgreSQL",
                    "Google BigQuery"
                ],
                "image": "https://images.pexels.com/photos/1181677/pexels-photo-1181677.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Real-time Streaming Data Pipeline",
                "description": "Create a scalable data pipeline for processing streaming data from multiple sources with automated validation and monitoring",
                "technologies": [
                    "Python",
                    "Apache Spark",
                    "Airflow",
                    "PostgreSQL"
                ],
                "image": "https://images.pexels.com/photos/1181677/pexels-photo-1181677.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master data engineering fundamentals and pipeline design",
            "Gain proficiency in SQL and database management",
            "Learn workflow automation with Apache Airflow",
            "Understand big data processing with Apache Spark",
            "Build scalable ETL/ELT pipelines for production use",
            "Deploy data solutions to cloud platforms",
            "Develop skills in data quality and validation",
            "Create portfolio-ready data engineering projects"
        ],
        "prerequisites": [
            "Basic programming knowledge (Python preferred)",
            "Understanding of databases and SQL basics",
            "Familiarity with command line operations",
            "Access to computer with internet connection"
        ],
        "courseOutcomes": [
            "Production-ready data engineering skills for ETL/ELT pipelines",
            "Hands-on experience with modern data engineering tools",
            "Portfolio projects demonstrating end-to-end data workflows",
            "Preparation for data engineer and analytics engineer roles",
            "Understanding of cloud data platforms and deployment",
            "Ability to design and optimize data processing systems"
        ],
        "toolsAndResources": {
            "platform": "Local setup + Cloud platforms",
            "libraries": [
                "Python",
                "Pandas",
                "Apache Airflow",
                "Apache Spark",
                "PostgreSQL"
            ],
            "cloudPlatforms": [
                "Google BigQuery",
                "AWS Redshift",
                "Azure Synapse"
            ],
            "versionControl": "GitHub for code management and portfolio",
            "assessment": [
                "Weekly hands-on labs",
                "Pipeline projects",
                "Final capstone project"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "Design ETL pipeline for e-commerce data",
                    "Research real-world data engineering case studies",
                    "Create data flow diagrams for business scenarios"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "Set up PostgreSQL database locally",
                    "Import and query sample sales datasets",
                    "Write complex SQL joins and aggregations"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Clean and transform messy customer data",
                    "Automate data validation with Python scripts",
                    "Build data processing pipelines with Pandas"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Create Airflow DAGs for data workflows",
                    "Set up automated scheduling and monitoring",
                    "Implement error handling and retry logic"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Process large datasets with Spark",
                    "Compare Spark vs Pandas performance",
                    "Optimize Spark jobs for efficiency"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalSkills": "Proficiency in data engineering tools and concepts",
            "projectQuality": "End-to-end pipeline implementation and documentation",
            "automation": "Effective use of scheduling and monitoring tools",
            "scalability": "Design of efficient and scalable data processing systems"
        }
    },
    "generative-ai-foundations": {
        "title": "Gen AI Foundations Track — 2025 Edition",
        "description": "Introduction to GenAI concepts, large language models, and prompt engineering techniques. Transform industries with AI-powered content creation and automation.",
        "duration": "6 weeks (60 hours)",
        "level": "Starter",
        "mode": "Online/Offline",
        "price": "₹7,000",
        "originalPrice": "₹10,000",
        "rating": 4.8,
        "students": 412,
        "nextBatch": "September 1, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-purple-500 to-purple-600",
        "icon": "Cpu",
        "image": "https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "OpenAI API",
            "Hugging Face",
            "LangChain",
            "Streamlit",
            "DALL·E",
            "Stable Diffusion",
            "Google Colab"
        ],
        "mentor": {
            "name": "Dr. Arjun Patel",
            "role": "AI Research Scientist",
            "company": "Quantiphi",
            "image": "https://images.pexels.com/photos/1239291/pexels-photo-1239291.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "12+ years in AI research and generative models"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Introduction to Generative AI",
                "duration": "10 hours",
                "topics": [
                    "Core concepts: What is Generative AI?",
                    "Real-world use cases across industries",
                    "Comparison: Generative AI vs Traditional AI",
                    "Industry applications in marketing, design, and automation",
                    "Hands-on: Demo of ChatGPT, DALL·E, and GitHub Copilot",
                    "Discussion of business impact and opportunities"
                ]
            },
            {
                "week": "2",
                "title": "Large Language Models (LLMs)",
                "duration": "10 hours",
                "topics": [
                    "LLMs explained: Architecture and capabilities",
                    "How GPT works: Transformer architecture and training",
                    "Prompt engineering basics and best practices",
                    "Zero-shot, few-shot, and chain-of-thought techniques",
                    "Hands-on: Text generation using OpenAI API (GPT)",
                    "Experimentation with different prompt styles"
                ]
            },
            {
                "week": "3",
                "title": "Image Generation Models",
                "duration": "10 hours",
                "topics": [
                    "Introduction to Stable Diffusion, DALL·E, and Midjourney",
                    "How image generation works: Diffusion models and CLIP",
                    "Text-to-image prompt engineering techniques",
                    "Comparing outputs from different models",
                    "Hands-on: Create images from text prompts",
                    "Exploring creative and commercial applications"
                ]
            },
            {
                "week": "4",
                "title": "Building with Generative AI APIs",
                "duration": "10 hours",
                "topics": [
                    "Setting up and using API keys securely",
                    "API basics: Authentication, endpoints, rate limits",
                    "Creating chatbot-like applications",
                    "Using Hugging Face models and transformers library",
                    "Hands-on: Build a simple conversational AI",
                    "Integrating multiple AI services"
                ]
            },
            {
                "week": "5",
                "title": "Enhancing Outputs & Ethics",
                "duration": "10 hours",
                "topics": [
                    "Advanced prompt engineering and optimization",
                    "Combining text and image generation workflows",
                    "Multimodal generation and creative applications",
                    "Ethical considerations: Bias, misuse, and copyright",
                    "Hands-on: Fine-tune prompts for quality and creativity",
                    "Responsible AI practices and guidelines"
                ]
            },
            {
                "week": "6",
                "title": "Final Project & Application Development",
                "duration": "10 hours",
                "topics": [
                    "Project planning and scope definition",
                    "End-to-end application development",
                    "Combining LLM and image generation APIs",
                    "User interface design with Streamlit",
                    "Testing, debugging, and optimization",
                    "Portfolio presentation and project demo"
                ]
            }
        ],
        "projects": [
            {
                "title": "AI-Powered Travel Itinerary & Poster Generator",
                "description": "Build an end-to-end application that generates personalized travel plans using LLM and creates matching travel posters using image AI",
                "technologies": [
                    "Python",
                    "OpenAI API",
                    "DALL·E",
                    "Streamlit",
                    "Jupyter Notebook"
                ],
                "image": "https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "AI Content Creation Suite",
                "description": "Develop a multi-purpose content generation tool for marketing copy, social media posts, and visual assets",
                "technologies": [
                    "Python",
                    "OpenAI API",
                    "Hugging Face",
                    "Stable Diffusion"
                ],
                "image": "https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Understand generative AI concepts and applications",
            "Master prompt engineering for text and image generation",
            "Gain proficiency in working with AI APIs and models",
            "Learn to build end-to-end generative AI applications",
            "Develop skills in multimodal AI content creation",
            "Understand ethical implications of generative AI",
            "Create portfolio projects showcasing AI capabilities",
            "Prepare for roles in AI-powered product development"
        ],
        "prerequisites": [
            "Basic programming knowledge (Python preferred)",
            "Familiarity with web APIs and JSON",
            "Interest in creative applications of AI",
            "Access to computer with internet connection"
        ],
        "courseOutcomes": [
            "Practical skills in generative AI development",
            "Portfolio of AI-powered applications and demos",
            "Understanding of prompt engineering best practices",
            "Ability to integrate multiple AI services and APIs",
            "Knowledge of ethical AI development practices",
            "Preparation for AI product manager and developer roles"
        ],
        "toolsAndResources": {
            "platform": "Google Colab and Jupyter Notebook",
            "apis": [
                "OpenAI API",
                "Hugging Face API",
                "Stable Diffusion"
            ],
            "frameworks": [
                "Python",
                "Streamlit",
                "LangChain"
            ],
            "versionControl": "GitHub for project sharing and portfolio",
            "assessment": [
                "Weekly demos",
                "API integration projects",
                "Final application"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "Explore ChatGPT, DALL·E, and GitHub Copilot demos",
                    "Identify business use cases for generative AI",
                    "Compare traditional vs generative AI approaches"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "Sign up for OpenAI API and generate text responses",
                    "Experiment with different prompt engineering techniques",
                    "Build a simple text generation script"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Create images using DALL·E or Stable Diffusion",
                    "Test various text-to-image prompts",
                    "Compare outputs from different image models"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Build Python script with OpenAI API integration",
                    "Create simple conversational agent",
                    "Experiment with Hugging Face transformers"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Optimize prompts for travel itinerary generation",
                    "Generate coordinated text and image content",
                    "Analyze ethical implications of AI outputs"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalImplementation": "Successful API integration and application functionality",
            "creativity": "Innovative use of generative AI capabilities",
            "promptEngineering": "Effective prompt design and optimization",
            "ethicalConsiderations": "Understanding of responsible AI practices"
        }
    },
    "data-science-professional-program": {
        "title": "Data Science Professional Program — 2025 Edition",
        "description": "Build expertise in data science with hands-on experience in Python, machine learning, and advanced analytics. Master the complete data science workflow from data wrangling to model deployment and storytelling.",
        "duration": "12 weeks (144 hours)",
        "level": "Professional",
        "mode": "Online/Offline",
        "price": "₹45,000",
        "originalPrice": "₹65,000",
        "rating": 4.9,
        "students": 156,
        "nextBatch": "September 15, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-purple-500 to-purple-600",
        "icon": "Database",
        "image": "https://images.pexels.com/photos/590022/pexels-photo-590022.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "Pandas",
            "NumPy",
            "Matplotlib",
            "Seaborn",
            "SQL",
            "Power BI",
            "Tableau",
            "Scikit-learn",
            "Jupyter Notebook",
            "Git",
            "GitHub",
            "Kaggle"
        ],
        "mentor": {
            "name": "Dr. Priya Sharma",
            "role": "Lead Data Scientist",
            "company": "Microsoft India",
            "image": "https://images.pexels.com/photos/774909/pexels-photo-774909.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "12+ years in data science and analytics across fintech and tech"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Advanced Python for Data Science",
                "duration": "12 hours",
                "topics": [
                    "Python refresher: variables, loops, functions, comprehensions",
                    "Writing production-ready code with error handling and logging",
                    "Efficient data structures for speed and memory optimization",
                    "Modular functions and documentation with docstrings",
                    "Advanced Python concepts: generators, lambda functions",
                    "Hands-on: Complex data problems using advanced Python"
                ]
            },
            {
                "week": "2",
                "title": "Data Manipulation with Pandas & NumPy",
                "duration": "12 hours",
                "topics": [
                    "Advanced Pandas: multi-index DataFrames, merging/joining",
                    "GroupBy operations and handling missing data effectively",
                    "DateTime manipulation and time series basics",
                    "NumPy for speed: vectorized operations and broadcasting",
                    "Statistical and visual methods for outlier detection",
                    "Hands-on: Clean and transform real-world messy datasets"
                ]
            },
            {
                "week": "3",
                "title": "Exploratory Data Analysis (EDA)",
                "duration": "12 hours",
                "topics": [
                    "Descriptive statistics: mean, median, skewness, kurtosis",
                    "Correlation and covariance analysis for relationships",
                    "Visual EDA: pair plots, heatmaps, boxplots, violin plots",
                    "Identifying data quality issues and anomalies",
                    "Advanced visualization techniques with custom themes",
                    "Hands-on: Comprehensive EDA on Kaggle datasets"
                ]
            },
            {
                "week": "4",
                "title": "Data Visualization Mastery",
                "duration": "12 hours",
                "topics": [
                    "Advanced Matplotlib/Seaborn: custom themes and subplots",
                    "Interactive visualizations with Plotly and Dash",
                    "Storytelling with data and design principles",
                    "Dashboard creation with real-time updates",
                    "Annotations, interactive elements, and user experience",
                    "Hands-on: Build comprehensive data story dashboard"
                ]
            },
            {
                "week": "5",
                "title": "SQL for Data Science",
                "duration": "12 hours",
                "topics": [
                    "Advanced SQL: complex joins, subqueries, and CTEs",
                    "Window functions: ROW_NUMBER, RANK, LAG/LEAD",
                    "Aggregation, transformation, pivoting, and rolling aggregates",
                    "Python + SQL integration for automated ETL processes",
                    "Query optimization techniques for large databases",
                    "Hands-on: Complex SQL queries and Python integration"
                ]
            },
            {
                "week": "6",
                "title": "Introduction to Machine Learning",
                "duration": "12 hours",
                "topics": [
                    "Supervised learning: regression and classification algorithms",
                    "Model evaluation: accuracy, precision, recall, F1, ROC-AUC",
                    "Feature engineering basics and categorical variable handling",
                    "Cross-validation techniques and model selection",
                    "Scikit-learn ecosystem and best practices",
                    "Hands-on: Train and evaluate models on real datasets"
                ]
            },
            {
                "week": "7",
                "title": "Unsupervised Learning & Dimensionality Reduction",
                "duration": "12 hours",
                "topics": [
                    "Clustering algorithms: K-Means, DBSCAN, hierarchical",
                    "Dimensionality reduction: PCA, t-SNE, UMAP",
                    "Customer segmentation and market basket analysis",
                    "Anomaly detection techniques and applications",
                    "Feature engineering for supervised models",
                    "Hands-on: Customer segmentation and high-dimensional visualization"
                ]
            },
            {
                "week": "8",
                "title": "Feature Engineering & Model Optimization",
                "duration": "12 hours",
                "topics": [
                    "Advanced encoding techniques: one-hot, target, embeddings",
                    "Scaling and normalization: StandardScaler, MinMaxScaler",
                    "Cross-validation strategies: k-fold, stratified, time series",
                    "Hyperparameter tuning: grid search, random search, Bayesian",
                    "AutoML tools and feature stores integration",
                    "Hands-on: End-to-end model pipeline optimization"
                ]
            },
            {
                "week": "9",
                "title": "Time Series Analysis",
                "duration": "12 hours",
                "topics": [
                    "Time series components: trend, seasonality, noise analysis",
                    "Forecasting models: ARIMA, SARIMA, Prophet",
                    "Introduction to LSTM for time series prediction",
                    "Model evaluation for time series data",
                    "Real-world applications: sales, stock prices, demand forecasting",
                    "Hands-on: Complete forecasting project with evaluation"
                ]
            },
            {
                "week": "10",
                "title": "Storytelling with Data & Dashboard Development",
                "duration": "12 hours",
                "topics": [
                    "Data storytelling frameworks and narrative structures",
                    "Advanced dashboard tools: Power BI, Tableau, Streamlit",
                    "Business KPIs and metric design for stakeholders",
                    "Presentation techniques and avoiding misrepresentation",
                    "Interactive dashboard deployment and maintenance",
                    "Hands-on: Business dashboard with stakeholder presentation"
                ]
            },
            {
                "week": "11",
                "title": "Real-World Project Work",
                "duration": "12 hours",
                "topics": [
                    "Industry dataset selection and problem scoping",
                    "Full pipeline development: ingestion to deployment",
                    "Team collaboration using Git and GitHub workflows",
                    "Code documentation and version control best practices",
                    "Project management and agile methodologies",
                    "Hands-on: Complete real-world data science project"
                ]
            },
            {
                "week": "12",
                "title": "Capstone Project Presentation",
                "duration": "12 hours",
                "topics": [
                    "Project showcase and technical presentation skills",
                    "Peer review and constructive feedback sessions",
                    "GitHub portfolio creation with documentation",
                    "Industry interview preparation and resume building",
                    "Networking and career development strategies",
                    "Final project delivery and assessment"
                ]
            }
        ],
        "projects": [
            {
                "title": "Customer Churn Prediction",
                "description": "Build a comprehensive churn prediction model for telecom industry using advanced ML techniques and feature engineering",
                "technologies": [
                    "Python",
                    "Scikit-learn",
                    "Pandas",
                    "XGBoost"
                ],
                "image": "https://images.pexels.com/photos/3183150/pexels-photo-3183150.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "COVID-19 Analytics Dashboard",
                "description": "Create an interactive dashboard tracking cases, deaths, vaccinations with geospatial analysis and trend forecasting",
                "technologies": [
                    "Python",
                    "Plotly",
                    "Dash",
                    "Prophet"
                ],
                "image": "https://images.pexels.com/photos/3951628/pexels-photo-3951628.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Credit Risk Analysis",
                "description": "Develop a sophisticated credit risk assessment model for banking sector with regulatory compliance considerations",
                "technologies": [
                    "Python",
                    "Scikit-learn",
                    "SQL",
                    "Tableau"
                ],
                "image": "https://images.pexels.com/photos/164527/pexels-photo-164527.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Sales Forecasting System",
                "description": "Build an end-to-end sales forecasting system with time series analysis and automated reporting",
                "technologies": [
                    "Python",
                    "Prophet",
                    "Streamlit",
                    "SQL"
                ],
                "image": "https://images.pexels.com/photos/590020/pexels-photo-590020.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Perform complex data wrangling and cleaning operations on real-world datasets",
            "Conduct advanced exploratory data analysis with professional visualizations",
            "Build and optimize predictive models using machine learning algorithms",
            "Master SQL for data extraction, transformation, and analysis",
            "Create compelling dashboards and communicate insights through storytelling",
            "Apply complete data science workflows to solve business problems",
            "Develop production-ready code with proper documentation and version control",
            "Understand time series analysis and forecasting techniques"
        ],
        "prerequisites": [
            "Basic Python programming knowledge (variables, loops, functions)",
            "Understanding of basic mathematics and statistics",
            "Familiarity with Excel or similar data tools",
            "Bachelor's degree or equivalent work experience",
            "Strong analytical thinking and problem-solving skills"
        ],
        "courseOutcomes": [
            "Industry-ready data scientist with end-to-end project experience",
            "Professional portfolio with documented real-world projects",
            "Advanced SQL and Python skills for data manipulation and analysis",
            "Expertise in machine learning model development and optimization",
            "Proficiency in data visualization and storytelling techniques",
            "Preparation for senior data analyst and data scientist roles",
            "Understanding of MLOps and model deployment best practices",
            "Network of industry professionals and career guidance"
        ],
        "toolsAndResources": {
            "platform": "Jupyter Notebook, VS Code, Google Colab",
            "libraries": [
                "Python 3.x",
                "Pandas 2.x",
                "NumPy",
                "Scikit-learn",
                "Matplotlib",
                "Seaborn",
                "Plotly",
                "XGBoost",
                "Prophet"
            ],
            "databases": [
                "PostgreSQL",
                "MySQL",
                "BigQuery"
            ],
            "visualization": [
                "Tableau",
                "Power BI",
                "Streamlit",
                "Dash"
            ],
            "versionControl": "Git, GitHub with collaborative workflows",
            "cloud": "AWS, GCP, Azure for scalable data processing",
            "assessment": [
                "Weekly coding assignments",
                "Mid-term project evaluation",
                "Final capstone project",
                "Peer code reviews"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "Advanced Python functions for data processing tasks",
                    "Error handling and logging implementation",
                    "Memory-efficient data structure optimization"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "Real-world dataset cleaning and transformation",
                    "Performance benchmarking: Pandas vs NumPy",
                    "Advanced time series data manipulation"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Comprehensive EDA on e-commerce dataset",
                    "Statistical analysis and hypothesis testing",
                    "Advanced correlation and causation analysis"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Interactive dashboard creation with Plotly",
                    "Custom visualization themes and branding",
                    "Data story presentation preparation"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Complex SQL query optimization challenges",
                    "Automated ETL pipeline with Python-SQL integration",
                    "Database performance tuning exercises"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalSkills": "Proficiency in Python, SQL, and ML libraries with clean code practices",
            "projectExecution": "Complete end-to-end data science workflow implementation",
            "dataInsights": "Ability to extract meaningful insights and business value from data",
            "communication": "Clear presentation of technical findings to business stakeholders",
            "codeQuality": "Well-documented, modular, and maintainable code with version control",
            "industryReadiness": "Understanding of data science best practices and MLOps principles"
        }
    },
    "sql-for-data-professionals": {
        "title": "SQL for Data Professionals Track — 2025 Edition",
        "description": "Master advanced SQL techniques for data analysis, database design, and query optimization. Essential for data professionals working with relational databases.",
        "duration": "6 weeks (60 hours)",
        "level": "Starter",
        "mode": "Online/Offline",
        "price": "₹7,000",
        "originalPrice": "₹10,000",
        "rating": 4.6,
        "students": 267,
        "nextBatch": "September 1, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-teal-500 to-teal-600",
        "icon": "Database",
        "image": "https://images.pexels.com/photos/1181677/pexels-photo-1181677.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "SQL",
            "PostgreSQL",
            "MySQL",
            "DBeaver",
            "pgAdmin",
            "Git",
            "AWS RDS",
            "GCP Cloud SQL",
            "Apache Superset",
            "Metabase"
        ],
        "mentor": {
            "name": "Amit Gupta",
            "role": "Database Architect",
            "company": "Zensar Technologies",
            "image": "https://images.pexels.com/photos/774909/pexels-photo-774909.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "12+ years in database design and SQL optimization"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Database Foundations & Basic SQL",
                "duration": "10 hours",
                "topics": [
                    "Introduction to databases: Relational vs NoSQL overview",
                    "Installing & configuring PostgreSQL/MySQL locally",
                    "GUI tools setup: DBeaver, pgAdmin configuration",
                    "Basic SQL: SELECT, filtering (WHERE), sorting (ORDER BY)",
                    "Hands-on lab: Installation, first queries, GUI exploration",
                    "Market context: PostgreSQL/MySQL in Bengaluru startups"
                ]
            },
            {
                "week": "2",
                "title": "Data Manipulation, Schema Design & Indexes",
                "duration": "10 hours",
                "topics": [
                    "Creating tables: Data types and constraints (PRIMARY KEY, FOREIGN KEY)",
                    "CRUD operations: INSERT, UPDATE, DELETE with best practices",
                    "Working with NULL values: COALESCE, NULLIF, IS NULL",
                    "Introduction to indexes and performance impact",
                    "Hands-on lab: Design product catalog or library database",
                    "Project integration: Start building e-commerce analytics schema"
                ]
            },
            {
                "week": "3",
                "title": "Advanced Querying, Joins & Set Operations",
                "duration": "10 hours",
                "topics": [
                    "Joins mastery: INNER, LEFT, RIGHT, FULL, self-joins",
                    "Subqueries and derived tables for complex analysis",
                    "Set operations: UNION, INTERSECT, EXCEPT",
                    "Multi-table queries for business analytics scenarios",
                    "Hands-on lab: Simulate customer support dashboard",
                    "Market trend: Joins as foundation for analytics roles"
                ]
            },
            {
                "week": "4",
                "title": "Aggregations, Window Functions & Stored Procedures",
                "duration": "10 hours",
                "topics": [
                    "Aggregate functions: COUNT, SUM, AVG, MIN, MAX with GROUP BY",
                    "HAVING clause for filtered aggregations",
                    "Window functions: ROW_NUMBER, RANK, DENSE_RANK, running totals",
                    "Introduction to stored procedures: Syntax, parameters, control flow",
                    "Hands-on lab: Sales summary reports and validation procedures",
                    "Advanced practice: Sales aggregation with anomaly detection"
                ]
            },
            {
                "week": "5",
                "title": "Data Quality, Automation & CI/CD",
                "duration": "10 hours",
                "topics": [
                    "Stored procedures deep dive: Complex logic, error handling",
                    "Automating SQL workflows: Scheduling with pgAgent/cron",
                    "Data quality and validation in stored procedures",
                    "Version control for SQL: Git workflows and best practices",
                    "CI/CD for databases: Testing with pgTAP, deployment strategies",
                    "Cloud integration: AWS RDS, GCP Cloud SQL deployment"
                ]
            },
            {
                "week": "6",
                "title": "Capstone Project – E-Commerce Analytics Platform",
                "duration": "10 hours",
                "topics": [
                    "Project scope: End-to-end reporting system design",
                    "Complex query implementation with business logic",
                    "Stored procedures for ETL and validation workflows",
                    "Automation setup and scheduling configuration",
                    "Dashboard creation with Superset/Metabase integration",
                    "Portfolio presentation and GitHub documentation"
                ]
            }
        ],
        "projects": [
            {
                "title": "E-Commerce Analytics Platform",
                "description": "Build a comprehensive reporting system with complex queries, stored procedures, automated ETL workflows, and interactive dashboards",
                "technologies": [
                    "PostgreSQL",
                    "SQL",
                    "Stored Procedures",
                    "Apache Superset",
                    "Git"
                ],
                "image": "https://images.pexels.com/photos/1181677/pexels-photo-1181677.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Customer Support Dashboard",
                "description": "Design and implement a multi-table analytics system for customer support with automated reporting and data validation",
                "technologies": [
                    "SQL",
                    "PostgreSQL",
                    "Joins",
                    "Window Functions"
                ],
                "image": "https://images.pexels.com/photos/590020/pexels-photo-590020.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master SQL fundamentals and advanced querying techniques",
            "Gain proficiency in database design and schema optimization",
            "Learn stored procedures for business logic implementation",
            "Develop skills in query optimization and performance tuning",
            "Understand data quality validation and automated workflows",
            "Build expertise in database CI/CD and version control",
            "Create production-ready analytics and reporting systems",
            "Prepare for data analyst and database developer roles"
        ],
        "prerequisites": [
            "Basic computer literacy and logical thinking",
            "No prior database experience required",
            "Willingness to learn structured query language",
            "Access to computer with internet connection"
        ],
        "courseOutcomes": [
            "Advanced SQL skills for complex data analysis and reporting",
            "Database design expertise with normalization and optimization",
            "Stored procedure development for automated data workflows",
            "Portfolio projects demonstrating end-to-end analytics systems",
            "Cloud database deployment and management experience",
            "Preparation for data engineer and analytics roles in Bengaluru market"
        ],
        "toolsAndResources": {
            "databases": [
                "PostgreSQL",
                "MySQL"
            ],
            "guiTools": [
                "DBeaver",
                "pgAdmin"
            ],
            "automation": [
                "cron",
                "pgAgent",
                "Python integration"
            ],
            "versionControl": "Git and GitHub for SQL script management",
            "cloudPlatforms": [
                "AWS RDS",
                "GCP Cloud SQL",
                "Azure Database"
            ],
            "visualization": [
                "Apache Superset",
                "Metabase"
            ],
            "assessment": [
                "Weekly SQL assignments",
                "Database projects",
                "Portfolio capstone"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "Install PostgreSQL and DBeaver locally",
                    "Create first database and write SELECT queries",
                    "Practice filtering, sorting, and limiting results"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "Design product catalog database schema",
                    "Practice CRUD operations with constraints",
                    "Benchmark queries with and without indexes"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Build customer support dashboard queries",
                    "Master different types of joins",
                    "Write subqueries for complex analysis"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Create sales summary reports with aggregations",
                    "Implement window functions for analytics",
                    "Write first stored procedure for validation"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Automate ETL workflows with stored procedures",
                    "Set up Git repository for SQL scripts",
                    "Deploy database to cloud platform"
                ]
            }
        ],
        "assessmentCriteria": {
            "sqlProficiency": "Advanced query writing and optimization skills",
            "databaseDesign": "Effective schema design and normalization",
            "automation": "Successful implementation of automated workflows",
            "documentation": "Clear code documentation and project presentation"
        }
    },
    "data-visualization-power-bi-tableau": {
        "title": "Data Visualizations Track — 2025 Edition",
        "description": "Master Power BI and Tableau to create compelling dashboards, KPIs, and interactive reports. Transform raw data into clear visual insights that drive business decisions.",
        "duration": "6 weeks (48 hours)",
        "level": "Starter",
        "mode": "Online/Offline",
        "price": "₹6,500",
        "originalPrice": "₹9,000",
        "rating": 4.6,
        "students": 278,
        "nextBatch": "September 8, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-purple-500 to-purple-600",
        "icon": "BarChart",
        "image": "https://images.pexels.com/photos/590022/pexels-photo-590022.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Power BI Desktop",
            "Tableau Public",
            "Microsoft Excel",
            "DAX",
            "SQL",
            "CSV/JSON",
            "Power Query",
            "Tableau Prep",
            "GitHub"
        ],
        "mentor": {
            "name": "Priya Sharma",
            "role": "Senior BI Developer",
            "company": "Wipro Limited",
            "image": "https://images.pexels.com/photos/415829/pexels-photo-415829.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "7+ years in business intelligence and data visualization"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Introduction to Data Visualization & Tools",
                "duration": "8 hours",
                "topics": [
                    "Why data visualization matters in business decisions",
                    "Overview of Power BI vs Tableau - features and use cases",
                    "Installing Power BI Desktop and Tableau Public",
                    "Navigating interfaces - menus, workspaces, data fields",
                    "Understanding dashboard anatomy and components",
                    "Building your first simple dashboard with sample data"
                ]
            },
            {
                "week": "2",
                "title": "Data Import & Preparation",
                "duration": "8 hours",
                "topics": [
                    "Connecting to multiple data sources (Excel, CSV, Web, Databases)",
                    "Data import techniques in Power BI and Tableau",
                    "Basic data cleaning and transformation workflows",
                    "Handling missing values, duplicates, and incorrect data types",
                    "Understanding data models, relationships, and star schema",
                    "Power Query basics and Tableau Prep introduction"
                ]
            },
            {
                "week": "3",
                "title": "Building Visuals",
                "duration": "8 hours",
                "topics": [
                    "Choosing appropriate chart types (bar, line, pie, area)",
                    "Creating tables, KPIs, and metric cards",
                    "Visual formatting: colors, fonts, labels, legends, tooltips",
                    "Best practices for clarity and accessibility",
                    "Custom visuals and advanced chart options",
                    "Design principles for effective data communication"
                ]
            },
            {
                "week": "4",
                "title": "Dashboards & Interactivity",
                "duration": "8 hours",
                "topics": [
                    "Combining visuals into cohesive dashboards",
                    "Adding interactivity with filters, slicers, and parameters",
                    "Implementing drill-throughs for detailed analysis",
                    "Using bookmarks and actions for storytelling",
                    "Multi-page dashboard design and navigation",
                    "Mobile-responsive dashboard considerations"
                ]
            },
            {
                "week": "5",
                "title": "Advanced Features",
                "duration": "8 hours",
                "topics": [
                    "Creating calculated columns and measures using DAX (Power BI)",
                    "Parameters, sets, and calculated fields in Tableau",
                    "Blending and combining data from multiple sources",
                    "Advanced calculations: profit margins, growth rates, rankings",
                    "Publishing to Power BI Service and Tableau Public",
                    "Sharing and collaboration features"
                ]
            },
            {
                "week": "6",
                "title": "Final Project & Portfolio",
                "duration": "8 hours",
                "topics": [
                    "Project brief: Global Sales & Profit Dashboard",
                    "End-to-end data preparation and modeling",
                    "Building comprehensive interactive dashboards",
                    "Applying storytelling and annotation techniques",
                    "Publishing and sharing professional dashboards",
                    "Presentation skills and gathering feedback"
                ]
            }
        ],
        "projects": [
            {
                "title": "Sales Performance Dashboard",
                "description": "Create an interactive dashboard analyzing regional sales performance, top products, and revenue trends with drill-down capabilities",
                "technologies": [
                    "Power BI",
                    "Excel",
                    "DAX",
                    "Power Query"
                ],
                "image": "https://images.pexels.com/photos/590020/pexels-photo-590020.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Customer Analytics Dashboard",
                "description": "Build a comprehensive customer segmentation and behavior analysis dashboard with interactive filters and KPIs",
                "technologies": [
                    "Tableau",
                    "CSV Data",
                    "Calculated Fields",
                    "Parameters"
                ],
                "image": "https://images.pexels.com/photos/3183150/pexels-photo-3183150.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Financial KPI Dashboard",
                "description": "Develop a financial metrics dashboard showing profit/loss, budget vs actual, and financial health indicators",
                "technologies": [
                    "Power BI",
                    "DAX",
                    "Multiple Data Sources",
                    "Bookmarks"
                ],
                "image": "https://images.pexels.com/photos/186461/pexels-photo-186461.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Global Sales & Profit Dashboard",
                "description": "Complete capstone project combining multiple data sources into an executive-level global business dashboard",
                "technologies": [
                    "Tableau",
                    "Multiple Sources",
                    "Advanced Calculations",
                    "Storytelling"
                ],
                "image": "https://images.pexels.com/photos/590016/pexels-photo-590016.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master Power BI Desktop and Tableau Public interfaces and workflows",
            "Connect to and prepare data from various sources efficiently",
            "Create compelling and interactive data visualizations",
            "Build professional dashboards with proper design principles",
            "Implement advanced features like DAX calculations and parameters",
            "Develop storytelling skills for data-driven presentations",
            "Understand best practices for dashboard design and user experience",
            "Prepare for BI analyst and data visualization specialist roles"
        ],
        "prerequisites": [
            "Basic computer literacy and Excel knowledge",
            "Understanding of basic business metrics",
            "No prior experience with BI tools required",
            "Access to computer with internet connection"
        ],
        "courseOutcomes": [
            "Proficiency in both Power BI and Tableau platforms",
            "Portfolio of published dashboards for job applications",
            "Skills to transform raw data into business insights",
            "Understanding of data visualization best practices",
            "Ability to present data stories effectively to stakeholders",
            "Preparation for business intelligence and analytics roles"
        ],
        "toolsAndResources": {
            "platform": "Power BI Desktop, Tableau Public (both free)",
            "libraries": [
                "Power BI Desktop",
                "Tableau Public",
                "Power Query",
                "DAX",
                "Tableau Prep"
            ],
            "dataSources": [
                "Public datasets",
                "Kaggle",
                "World Bank Open Data",
                "Government portals"
            ],
            "versionControl": "GitHub for dashboard documentation",
            "assessment": [
                "Weekly dashboard assignments",
                "Peer review sessions",
                "Final capstone project"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "Install and explore Power BI and Tableau interfaces",
                    "Build first dashboard with sample retail data",
                    "Present dashboard to class for feedback"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "Import and clean public dataset from multiple sources",
                    "Document data preparation steps",
                    "Create data model with relationships"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Create dashboard with various chart types",
                    "Apply formatting and design best practices",
                    "Conduct peer review for design feedback"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Build multi-page interactive dashboard",
                    "Implement filters, slicers, and drill-through actions",
                    "Create bookmark-driven data story"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Create advanced calculations and metrics",
                    "Blend multiple data sources",
                    "Publish dashboard to cloud platforms"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalSkills": "Proficient use of Power BI and Tableau features",
            "designQuality": "Clear, intuitive, and visually appealing dashboards",
            "interactivity": "Effective use of filters, drill-downs, and navigation",
            "storytelling": "Ability to guide viewers through data insights"
        }
    },
    "machine-learning-basics": {
        "title": "Machine Learning Professional Program — 2025 Edition",
        "description": "Master machine learning algorithms from fundamentals to deployment. Build production-ready ML models with hands-on experience in supervised, unsupervised, and deep learning techniques.",
        "duration": "12 weeks (144 hours)",
        "level": "Professional",
        "mode": "Online/Offline",
        "price": "₹48,000",
        "originalPrice": "₹70,000",
        "rating": 4.8,
        "students": 198,
        "nextBatch": "September 22, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-green-500 to-green-600",
        "icon": "Brain",
        "image": "https://images.pexels.com/photos/3861958/pexels-photo-3861958.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "Scikit-learn",
            "Pandas",
            "NumPy",
            "Matplotlib",
            "Seaborn",
            "TensorFlow",
            "PyTorch",
            "OpenCV",
            "Git",
            "Jupyter Notebook",
            "Kaggle"
        ],
        "mentor": {
            "name": "Arjun Patel",
            "role": "Principal ML Engineer",
            "company": "Amazon Web Services",
            "image": "https://images.pexels.com/photos/774909/pexels-photo-774909.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "10+ years in ML engineering and AI system architecture"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "ML Foundations & Environment Setup",
                "duration": "12 hours",
                "topics": [
                    "Machine learning applications across industries (healthcare, finance, e-commerce)",
                    "ML lifecycle: problem definition to deployment and monitoring",
                    "Python ecosystem setup: Anaconda, JupyterLab, essential libraries",
                    "Types of data: structured, unstructured, tabular, image, text",
                    "First ML workflow implementation and dataset exploration",
                    "Cloud notebooks: Google Colab, Kaggle Kernels for collaboration"
                ]
            },
            {
                "week": "2",
                "title": "Data Preparation",
                "duration": "12 hours",
                "topics": [
                    "Missing data handling: imputation strategies (mean, median, KNN, iterative)",
                    "Categorical encoding: one-hot, label, target, embeddings for high-cardinality",
                    "Feature scaling: standardization, normalization, robust scaling techniques",
                    "Initial feature engineering: creating features, binning, interaction terms",
                    "Data quality assessment and validation techniques",
                    "Hands-on: Clean real-world messy datasets (sales, customer, IoT)"
                ]
            },
            {
                "week": "3",
                "title": "Supervised Learning: Regression Models",
                "duration": "12 hours",
                "topics": [
                    "Linear regression: theory, assumptions, mathematical foundations",
                    "Regularization techniques: Ridge, Lasso regression applications",
                    "Evaluation metrics: MSE, RMSE, R², MAE, and interpretation",
                    "Model validation and cross-validation strategies",
                    "Practical modeling with scikit-learn ecosystem",
                    "Hands-on: House price prediction with advanced regression techniques"
                ]
            },
            {
                "week": "4",
                "title": "Supervised Learning: Classification Models",
                "duration": "12 hours",
                "topics": [
                    "Logistic regression: binary, multiclass, decision boundaries",
                    "Decision trees and random forests: algorithms and interpretability",
                    "Evaluation metrics: accuracy, precision, recall, F1, ROC-AUC",
                    "Overfitting and underfitting: detection and mitigation strategies",
                    "Feature importance analysis and model interpretability",
                    "Hands-on: Fraud detection and customer churn classification"
                ]
            },
            {
                "week": "5",
                "title": "Ensemble Methods",
                "duration": "12 hours",
                "topics": [
                    "Bagging techniques: Random Forests implementation and tuning",
                    "Boosting algorithms: XGBoost, LightGBM with GPU support",
                    "Stacking methods: combining multiple models for better performance",
                    "Advanced hyperparameter tuning: grid search, random search, Bayesian",
                    "Categorical feature handling in gradient boosting",
                    "Hands-on: Kaggle competition using ensemble methods"
                ]
            },
            {
                "week": "6",
                "title": "Unsupervised Learning",
                "duration": "12 hours",
                "topics": [
                    "Clustering algorithms: K-Means (elbow method), DBSCAN, hierarchical",
                    "Dimensionality reduction: PCA, t-SNE, UMAP for visualization",
                    "Applications: customer segmentation, anomaly detection, feature extraction",
                    "Evaluation metrics for unsupervised learning",
                    "Market basket analysis and recommendation systems basics",
                    "Hands-on: Customer segmentation and high-dimensional data visualization"
                ]
            },
            {
                "week": "7",
                "title": "Model Selection & Optimization",
                "duration": "12 hours",
                "topics": [
                    "Cross-validation strategies: k-fold, stratified, time series splits",
                    "Advanced hyperparameter optimization: Bayesian optimization, Optuna",
                    "Bias-variance tradeoff: diagnosis and model complexity management",
                    "Automated Machine Learning (AutoML): Auto-sklearn, TPOT",
                    "Model interpretability: SHAP, LIME for explainable AI",
                    "Hands-on: Complete model optimization pipeline development"
                ]
            },
            {
                "week": "8",
                "title": "Deep Learning",
                "duration": "12 hours",
                "topics": [
                    "Neural network fundamentals: perceptrons, activation functions, backpropagation",
                    "TensorFlow and Keras APIs: model building and training workflows",
                    "Training optimization: callbacks, early stopping, learning rate scheduling",
                    "Visualization: training curves, metrics, embedding spaces",
                    "Transfer learning and pre-trained model utilization",
                    "Hands-on: Neural network training on tabular and image datasets"
                ]
            },
            {
                "week": "9",
                "title": "Computer Vision Basics",
                "duration": "12 hours",
                "topics": [
                    "Image preprocessing: resizing, normalization, data augmentation",
                    "OpenCV for feature extraction: edges, corners, histograms",
                    "Convolutional Neural Networks: convolution, pooling, architecture design",
                    "Transfer learning with pre-trained models (ResNet, EfficientNet)",
                    "Medical imaging and product recognition applications",
                    "Hands-on: Image classifier development and deployment"
                ]
            },
            {
                "week": "10",
                "title": "Model Deployment",
                "duration": "12 hours",
                "topics": [
                    "Model serialization: joblib, pickle, ONNX format standards",
                    "API development: Flask, FastAPI for model serving endpoints",
                    "Containerization: Docker for reproducible deployments",
                    "Cloud deployment: AWS SageMaker, GCP AI Platform, Azure ML",
                    "MLOps principles: CI/CD, monitoring, model versioning",
                    "Hands-on: Deploy ML model as scalable REST API"
                ]
            },
            {
                "week": "11",
                "title": "Real-World Project Work",
                "duration": "12 hours",
                "topics": [
                    "Dataset selection: Kaggle, UCI, government open data sources",
                    "Full ML pipeline: data prep, feature engineering, modeling, evaluation",
                    "Team collaboration: GitHub workflows, code reviews, documentation",
                    "Testing strategies: unit tests, integration tests, model validation",
                    "Performance optimization and scalability considerations",
                    "Hands-on: Complete ML solution delivery on real-world problem"
                ]
            },
            {
                "week": "12",
                "title": "Capstone Project & Presentation",
                "duration": "12 hours",
                "topics": [
                    "Project delivery: comprehensive documentation and code organization",
                    "Technical presentation: methodology, results, business impact",
                    "Peer review sessions: code quality and architecture feedback",
                    "Portfolio development: GitHub showcase and LinkedIn optimization",
                    "Interview preparation: technical questions and project discussions",
                    "Industry networking and career development strategies"
                ]
            }
        ],
        "projects": [
            {
                "title": "House Price Prediction System",
                "description": "Build an end-to-end house price prediction system with advanced regression techniques and API deployment",
                "technologies": [
                    "Python",
                    "Scikit-learn",
                    "FastAPI",
                    "Docker"
                ],
                "image": "https://images.pexels.com/photos/106399/pexels-photo-106399.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Fraud Detection Engine",
                "description": "Develop a sophisticated fraud detection classifier optimized for precision and recall with real-time scoring",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "Scikit-learn",
                    "Flask"
                ],
                "image": "https://images.pexels.com/photos/50987/money-card-business-credit-card-50987.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Medical Image Classification",
                "description": "Create a CNN-based medical image classifier with preprocessing, training, and interpretability analysis",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "OpenCV",
                    "SHAP"
                ],
                "image": "https://images.pexels.com/photos/356040/pexels-photo-356040.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Customer Segmentation Platform",
                "description": "Build an unsupervised learning platform for customer segmentation with interactive visualization",
                "technologies": [
                    "Python",
                    "Scikit-learn",
                    "Plotly",
                    "Streamlit"
                ],
                "image": "https://images.pexels.com/photos/3184291/pexels-photo-3184291.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Understand and implement core ML algorithms from scratch and using libraries",
            "Master data preprocessing and feature engineering for optimal model performance",
            "Apply supervised, unsupervised, and ensemble learning techniques effectively",
            "Build and deploy production-ready ML models with proper monitoring",
            "Develop deep learning models using TensorFlow and PyTorch frameworks",
            "Implement computer vision solutions using CNNs and transfer learning",
            "Create end-to-end ML workflows from data to deployment",
            "Apply MLOps principles for sustainable and scalable ML systems"
        ],
        "prerequisites": [
            "Solid Python programming skills (functions, classes, data structures)",
            "Basic understanding of statistics and linear algebra",
            "Familiarity with data manipulation using Pandas and NumPy",
            "Understanding of mathematical concepts (calculus basics helpful)",
            "Experience with Jupyter notebooks and data analysis workflow"
        ],
        "courseOutcomes": [
            "Production-ready ML engineer with deployment experience",
            "Professional portfolio showcasing end-to-end ML projects",
            "Expertise in advanced ML algorithms and model optimization",
            "Proficiency in deep learning and computer vision applications",
            "Understanding of MLOps and model lifecycle management",
            "Preparation for senior ML engineer and AI specialist roles",
            "Knowledge of ethical AI principles and bias detection",
            "Industry network and career advancement opportunities"
        ],
        "toolsAndResources": {
            "platform": "Jupyter Notebook, Google Colab, Kaggle Kernels",
            "libraries": [
                "Scikit-learn",
                "TensorFlow 2.x",
                "PyTorch",
                "XGBoost",
                "LightGBM",
                "OpenCV",
                "SHAP",
                "Optuna"
            ],
            "cloud": [
                "AWS SageMaker",
                "Google Cloud AI Platform",
                "Azure Machine Learning",
                "Colab Pro"
            ],
            "deployment": [
                "Flask",
                "FastAPI",
                "Docker",
                "Kubernetes"
            ],
            "versionControl": "Git, GitHub, GitLab for collaborative development",
            "automation": "MLflow, DVC, Airflow for ML workflows",
            "assessment": [
                "Weekly coding challenges",
                "Algorithm implementation assignments",
                "Mid-term project evaluation",
                "Final capstone project presentation"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "ML workflow implementation on sample datasets",
                    "Environment setup and library configuration",
                    "Data type identification and preprocessing strategies"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "Advanced data cleaning on real-world messy datasets",
                    "Feature engineering techniques and validation",
                    "Handling missing data with multiple imputation methods"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Linear regression implementation from scratch and using libraries",
                    "Regularization techniques comparison and tuning",
                    "Regression model evaluation and interpretation"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Classification algorithm implementation and comparison",
                    "ROC curve analysis and threshold optimization",
                    "Feature importance analysis and model interpretability"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Ensemble method implementation and performance comparison",
                    "Kaggle competition submission using advanced ensembles",
                    "Hyperparameter optimization strategies"
                ]
            }
        ],
        "assessmentCriteria": {
            "algorithmUnderstanding": "Deep comprehension of ML algorithms and their mathematical foundations",
            "implementationSkills": "Ability to implement algorithms from scratch and use libraries effectively",
            "projectExecution": "Complete end-to-end ML pipeline development and deployment",
            "codeQuality": "Clean, efficient, and well-documented code with proper testing",
            "modelPerformance": "Optimal model selection, tuning, and evaluation techniques",
            "industryReadiness": "Understanding of MLOps, ethics, and production ML considerations"
        }
    },
    "cloud-fundamentals-data-ai": {
        "title": "Cloud Fundamentals for Data & AI — 2025 Edition",
        "description": "Master cloud computing essentials for data and AI workloads. Learn AWS, Azure, and GCP services for storage, compute, and machine learning deployment.",
        "duration": "6 weeks (48 hours)",
        "level": "Beginner",
        "mode": "Online/Offline",
        "price": "₹7,500",
        "originalPrice": "₹11,000",
        "rating": 4.5,
        "students": 189,
        "nextBatch": "September 22, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-sky-500 to-sky-600",
        "icon": "Cloud",
        "image": "https://images.pexels.com/photos/844124/pexels-photo-844124.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "AWS (S3, EC2, SageMaker)",
            "Microsoft Azure",
            "Google Cloud Platform",
            "Docker",
            "Kubernetes",
            "Python",
            "Jupyter Notebook",
            "APIs",
            "IAM Security"
        ],
        "mentor": {
            "name": "Suresh Reddy",
            "role": "Cloud Solutions Architect",
            "company": "Amazon Web Services",
            "image": "https://images.pexels.com/photos/2379005/pexels-photo-2379005.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "9+ years in cloud architecture and data engineering"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Cloud Computing Fundamentals",
                "duration": "8 hours",
                "topics": [
                    "What is cloud computing and its business benefits",
                    "Cloud service models: IaaS, PaaS, SaaS explained",
                    "Scalability, cost-effectiveness, and reliability advantages",
                    "Overview of major providers: AWS, Azure, GCP comparison",
                    "Setting up free-tier accounts and navigating dashboards",
                    "Understanding regions, availability zones, and global infrastructure"
                ]
            },
            {
                "week": "2",
                "title": "Cloud Storage & Databases",
                "duration": "8 hours",
                "topics": [
                    "Object storage: AWS S3, Azure Blob, GCP Cloud Storage",
                    "Uploading, organizing, and securing datasets in the cloud",
                    "Setting permissions, versioning, and lifecycle policies",
                    "Database services: RDS, Azure SQL, Cloud SQL overview",
                    "Connecting applications to cloud storage via APIs",
                    "Cost optimization strategies for data storage"
                ]
            },
            {
                "week": "3",
                "title": "Cloud Compute Services",
                "duration": "8 hours",
                "topics": [
                    "Virtual machines: AWS EC2, Azure VMs, GCP Compute Engine",
                    "Container services: ECS, Container Instances, Kubernetes Engine",
                    "Serverless computing: Lambda, Azure Functions, Cloud Functions",
                    "Choosing right compute service for different workloads",
                    "Deploying Python applications on various compute platforms",
                    "Auto-scaling and load balancing concepts"
                ]
            },
            {
                "week": "4",
                "title": "AI & Machine Learning in the Cloud",
                "duration": "8 hours",
                "topics": [
                    "Pre-built AI services: Vision, NLP, and Speech APIs",
                    "AWS Rekognition, Azure Cognitive Services, GCP AI APIs",
                    "Machine learning platforms: SageMaker, Azure ML, AI Platform",
                    "Training and deploying ML models in the cloud",
                    "Jupyter notebooks in cloud environments",
                    "Real-time inference and batch prediction services"
                ]
            },
            {
                "week": "5",
                "title": "Security & Cost Management",
                "duration": "8 hours",
                "topics": [
                    "Identity and Access Management (IAM) across platforms",
                    "Setting up users, roles, and permissions securely",
                    "Multi-factor authentication and security best practices",
                    "Cost monitoring tools and budget alerts setup",
                    "Resource optimization and rightsizing strategies",
                    "Compliance and data governance basics"
                ]
            },
            {
                "week": "6",
                "title": "Final Project - Cloud AI Application",
                "duration": "8 hours",
                "topics": [
                    "Project planning: Cloud-hosted sentiment analysis application",
                    "Data storage setup and ML model deployment",
                    "Building API endpoints for real-time predictions",
                    "Implementing security and cost controls",
                    "Documentation and architecture diagramming",
                    "Project presentation and peer review"
                ]
            }
        ],
        "projects": [
            {
                "title": "Cloud Data Storage Setup",
                "description": "Set up secure data storage across AWS S3, Azure Blob, and GCP Storage with proper access controls and cost optimization",
                "technologies": [
                    "AWS S3",
                    "Azure Blob",
                    "GCP Storage",
                    "IAM Policies"
                ],
                "image": "https://images.pexels.com/photos/1181677/pexels-photo-1181677.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Multi-Cloud VM Deployment",
                "description": "Deploy and manage Python applications across different cloud virtual machine services with monitoring and scaling",
                "technologies": [
                    "AWS EC2",
                    "Azure VMs",
                    "GCP Compute",
                    "Docker"
                ],
                "image": "https://images.pexels.com/photos/1181244/pexels-photo-1181244.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Serverless ML Inference API",
                "description": "Build serverless functions for ML model inference using AWS Lambda, Azure Functions, and GCP Cloud Functions",
                "technologies": [
                    "AWS Lambda",
                    "Azure Functions",
                    "Cloud Functions",
                    "ML APIs"
                ],
                "image": "https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Cloud-Hosted Sentiment Analysis App",
                "description": "Complete end-to-end AI application with cloud storage, ML training, API deployment, and web interface",
                "technologies": [
                    "Multi-cloud Setup",
                    "ML Services",
                    "APIs",
                    "Web Frontend"
                ],
                "image": "https://images.pexels.com/photos/3861969/pexels-photo-3861969.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Understand cloud computing fundamentals and service models",
            "Master data storage and management across major cloud platforms",
            "Deploy applications using various cloud compute services",
            "Implement AI and ML solutions in cloud environments",
            "Configure security and access management systems",
            "Optimize costs and monitor cloud resource usage",
            "Build complete cloud-native data and AI applications",
            "Prepare for cloud certifications and cloud-focused careers"
        ],
        "prerequisites": [
            "Basic understanding of programming (Python preferred)",
            "Familiarity with basic networking concepts",
            "General knowledge of databases and web applications",
            "Access to computer with internet for cloud platform access"
        ],
        "courseOutcomes": [
            "Hands-on experience with AWS, Azure, and GCP platforms",
            "Portfolio of cloud-deployed applications and ML models",
            "Understanding of cloud architecture and best practices",
            "Skills in cloud security and cost optimization",
            "Preparation for cloud solution architect and data engineer roles",
            "Foundation for pursuing cloud platform certifications"
        ],
        "toolsAndResources": {
            "platform": "AWS, Azure, GCP free tiers with hands-on labs",
            "libraries": [
                "Cloud SDKs",
                "boto3 (AWS)",
                "Azure SDK",
                "Google Cloud SDK",
                "Docker"
            ],
            "dataSources": [
                "Public datasets from cloud marketplaces",
                "Sample ML datasets",
                "Real-time APIs",
                "Open government data"
            ],
            "versionControl": "GitHub for cloud infrastructure documentation",
            "assessment": [
                "Platform-specific assignments",
                "Multi-cloud comparison projects",
                "Final capstone deployment"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "Create free accounts on AWS, Azure, and GCP",
                    "Navigate dashboards and explore service catalogs",
                    "Compare pricing models across platforms"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "Upload and organize datasets on all three platforms",
                    "Configure storage permissions and access policies",
                    "Test data access via APIs and SDKs"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Deploy Python script on VM, container, and serverless",
                    "Compare performance and costs across compute types",
                    "Set up monitoring and logging"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Use pre-built AI services for image/text analysis",
                    "Deploy simple ML model on cloud ML platforms",
                    "Create API endpoints for model inference"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Configure IAM roles and security policies",
                    "Set up cost monitoring and budget alerts",
                    "Implement resource tagging and optimization"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalSkills": "Proficient use of cloud services and APIs",
            "architecture": "Well-designed, scalable cloud solutions",
            "security": "Proper implementation of security best practices",
            "costOptimization": "Understanding and application of cost management"
        }
    },
    "apis-automation-python": {
        "title": "APIs & Automation with Python — 2025 Edition",
        "description": "Learn to integrate systems using APIs and automate business processes with Python. Build REST APIs, consume external services, and create automated workflows.",
        "duration": "6 weeks (48 hours)",
        "level": "Intermediate",
        "mode": "Online/Offline",
        "price": "₹7,000",
        "originalPrice": "₹10,000",
        "rating": 4.7,
        "students": 298,
        "nextBatch": "September 29, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-orange-500 to-orange-600",
        "icon": "Workflow",
        "image": "https://images.pexels.com/photos/1181298/pexels-photo-1181298.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python 3",
            "Flask",
            "FastAPI",
            "Requests",
            "JSON",
            "REST APIs",
            "Postman",
            "Automation Scripts",
            "Cron Jobs"
        ],
        "mentor": {
            "name": "Vikash Singh",
            "role": "Senior Backend Developer",
            "company": "Infosys Limited",
            "image": "https://images.pexels.com/photos/1222271/pexels-photo-1222271.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "8+ years in API development and system automation"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Introduction to APIs & Python Foundations",
                "duration": "8 hours",
                "topics": [
                    "Understanding APIs: what they are and business importance",
                    "REST vs SOAP architectures and when to use each",
                    "Python refresher: variables, functions, loops, error handling",
                    "Setting up development environment with Python and tools",
                    "Introduction to Postman for API testing and exploration",
                    "Exploring public APIs and understanding API documentation"
                ]
            },
            {
                "week": "2",
                "title": "Consuming APIs with Python",
                "duration": "8 hours",
                "topics": [
                    "HTTP methods: GET, POST, PUT, DELETE explained",
                    "Using Python's requests library for API calls",
                    "Parsing JSON responses and handling different data formats",
                    "Error handling: HTTP status codes, exceptions, retry logic",
                    "Working with query parameters and request headers",
                    "Saving API data to files and databases"
                ]
            },
            {
                "week": "3",
                "title": "API Authentication & Real-World Integrations",
                "duration": "8 hours",
                "topics": [
                    "Authentication methods: API keys, OAuth, Bearer tokens",
                    "Securing API credentials using environment variables",
                    "Integrating with popular APIs: weather, social media, payments",
                    "Handling rate limits and implementing exponential backoff",
                    "Building robust API clients with proper error handling",
                    "API versioning and backward compatibility considerations"
                ]
            },
            {
                "week": "4",
                "title": "Building REST APIs with Python",
                "duration": "8 hours",
                "topics": [
                    "Introduction to web frameworks: Flask vs FastAPI comparison",
                    "Creating API endpoints and defining routes",
                    "Handling different HTTP methods and request data",
                    "Returning JSON responses and proper status codes",
                    "API documentation with Swagger/OpenAPI",
                    "Testing APIs using Postman and automated tests"
                ]
            },
            {
                "week": "5",
                "title": "Process Automation with Python",
                "duration": "8 hours",
                "topics": [
                    "File system automation: reading, writing, organizing files",
                    "Data processing automation: cleaning, transforming, aggregating",
                    "Email automation: sending notifications with attachments",
                    "Scheduling scripts with Cron (Linux/Mac) and Task Scheduler (Windows)",
                    "Logging and monitoring automated processes",
                    "Building robust automation with error handling and recovery"
                ]
            },
            {
                "week": "6",
                "title": "Final Project - Automated Report Generator",
                "duration": "8 hours",
                "topics": [
                    "Project planning: automated data fetch and report system",
                    "API integration for real-time data collection",
                    "Data processing and analysis automation",
                    "Report generation in multiple formats (PDF, HTML, Excel)",
                    "Email delivery system with scheduling",
                    "Production deployment and monitoring setup"
                ]
            }
        ],
        "projects": [
            {
                "title": "Weather Data Collector",
                "description": "Build a Python script that fetches weather data from multiple APIs, processes it, and stores it in structured format",
                "technologies": [
                    "Python",
                    "Requests",
                    "Weather APIs",
                    "JSON Processing"
                ],
                "image": "https://images.pexels.com/photos/1118873/pexels-photo-1118873.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Social Media Integration Bot",
                "description": "Create automated bot that posts content to multiple social platforms and aggregates engagement metrics",
                "technologies": [
                    "Python",
                    "Social Media APIs",
                    "OAuth",
                    "Scheduling"
                ],
                "image": "https://images.pexels.com/photos/267350/pexels-photo-267350.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "RESTful Task Management API",
                "description": "Build a complete REST API for task management with CRUD operations, authentication, and documentation",
                "technologies": [
                    "FastAPI",
                    "SQLite",
                    "Swagger Docs",
                    "Authentication"
                ],
                "image": "https://images.pexels.com/photos/3183150/pexels-photo-3183150.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Automated Business Report Generator",
                "description": "Complete automation system that fetches data from APIs, processes it, generates reports, and emails stakeholders",
                "technologies": [
                    "Python",
                    "Multiple APIs",
                    "Report Generation",
                    "Email Automation"
                ],
                "image": "https://images.pexels.com/photos/590016/pexels-photo-590016.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master API consumption using Python's requests library",
            "Build robust REST APIs with Flask or FastAPI frameworks",
            "Implement various authentication methods for API security",
            "Automate repetitive business processes and workflows",
            "Create scheduled tasks and monitoring systems",
            "Develop error handling and logging best practices",
            "Integration skills for connecting different systems and services",
            "Prepare for backend developer and automation engineer roles"
        ],
        "prerequisites": [
            "Solid Python programming foundation (variables, functions, classes)",
            "Understanding of basic web concepts (HTTP, JSON)",
            "Familiarity with command line/terminal operations",
            "Basic knowledge of databases and file systems"
        ],
        "courseOutcomes": [
            "Proficiency in consuming and building REST APIs",
            "Portfolio of automation scripts and API projects",
            "Skills to integrate disparate systems and services",
            "Understanding of API security and best practices",
            "Ability to build production-ready automated workflows",
            "Preparation for full-stack developer and DevOps roles"
        ],
        "toolsAndResources": {
            "platform": "VS Code, PyCharm, or any Python IDE",
            "libraries": [
                "requests",
                "Flask",
                "FastAPI",
                "schedule",
                "smtplib",
                "json"
            ],
            "dataSources": [
                "Public APIs (OpenWeatherMap, GitHub, etc.)",
                "Social media APIs",
                "Financial data APIs",
                "Government open data APIs"
            ],
            "versionControl": "GitHub for API documentation and code sharing",
            "assessment": [
                "API integration assignments",
                "Automation script projects",
                "Final capstone project"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "Set up development environment and explore public APIs",
                    "Use Postman to test various API endpoints",
                    "Write Python scripts for basic HTTP requests"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "Build weather data fetcher with error handling",
                    "Create CSV export functionality from API data",
                    "Implement retry logic for failed requests"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Integrate with authenticated APIs using API keys",
                    "Build multi-API aggregator with rate limiting",
                    "Create secure credential management system"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Build REST API with multiple endpoints",
                    "Add request validation and error handling",
                    "Create API documentation with examples"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Automate file organization and cleanup tasks",
                    "Create email notification system with templates",
                    "Set up scheduled execution with monitoring"
                ]
            }
        ],
        "assessmentCriteria": {
            "codeQuality": "Clean, maintainable, and well-documented code",
            "functionality": "Working APIs and automation scripts that meet requirements",
            "errorHandling": "Robust error handling and logging implementation",
            "documentation": "Clear API documentation and usage instructions"
        }
    },
    "deep-learning-specialization": {
        "title": "Deep Learning Specialization — 2025 Edition",
        "description": "Master deep neural networks, CNNs, RNNs, Transformers, and GANs. Build production-ready AI models for computer vision, NLP, and generative AI applications.",
        "duration": "14 weeks (140+ hours)",
        "level": "Advanced",
        "mode": "Online/Offline",
        "price": "₹25,000",
        "originalPrice": "₹35,000",
        "rating": 4.8,
        "students": 187,
        "nextBatch": "September 15, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-purple-500 to-purple-600",
        "icon": "Brain",
        "image": "https://images.pexels.com/photos/3861969/pexels-photo-3861969.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Hugging Face Transformers",
            "OpenCV",
            "scikit-learn",
            "CUDA",
            "ONNX",
            "MLflow",
            "Weights & Biases"
        ],
        "mentor": {
            "name": "Dr. Ananya Sharma",
            "role": "Principal AI Research Scientist",
            "company": "Microsoft Research India",
            "image": "https://images.pexels.com/photos/3184338/pexels-photo-3184338.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "12+ years in deep learning research and AI model development"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Introduction to Deep Learning",
                "duration": "10 hours",
                "topics": [
                    "DL vs. ML: Why DL, when to use, advantages in feature learning",
                    "Neuron fundamentals: Perceptron, activation functions (ReLU, sigmoid, tanh)",
                    "Forward and backward propagation mechanisms",
                    "Hands-on: Implement a perceptron, visualize activation functions"
                ]
            },
            {
                "week": "2",
                "title": "Neural Network Foundations",
                "duration": "10 hours",
                "topics": [
                    "Building NNs from scratch: NumPy-based implementation",
                    "Loss functions: MSE, cross-entropy",
                    "Optimizers: SGD, momentum, Adam, RMSprop",
                    "Hands-on: Train a 2-layer NN on a toy dataset, compare optimizers"
                ]
            },
            {
                "week": "3",
                "title": "Deep Learning with TensorFlow & Keras",
                "duration": "10 hours",
                "topics": [
                    "TensorFlow/Keras API: Layers, models, callbacks",
                    "Training loop: Fit, validation, early stopping",
                    "Model evaluation: Accuracy, loss curves, confusion matrix",
                    "Hands-on: Build, train, and evaluate a DNN on MNIST/CIFAR-10"
                ]
            },
            {
                "week": "4",
                "title": "Regularization & Optimization Techniques",
                "duration": "10 hours",
                "topics": [
                    "Regularization: Dropout, batch normalization, weight decay",
                    "Optimization: Learning rate schedules (cosine, step), adaptive methods",
                    "Early stopping: Prevent overfitting, save best model",
                    "Hands-on: Apply techniques to improve model generalization"
                ]
            },
            {
                "week": "5",
                "title": "Convolutional Neural Networks (CNNs)",
                "duration": "10 hours",
                "topics": [
                    "CNN architecture: Convolution, pooling, padding, strides",
                    "Image classification: Build and train a CNN from scratch",
                    "Hands-on: Classify images (CIFAR-10), visualize filters"
                ]
            },
            {
                "week": "6",
                "title": "Advanced CNN Architectures",
                "duration": "10 hours",
                "topics": [
                    "ResNet, DenseNet, EfficientNet: Skip connections, dense blocks",
                    "Transfer learning: Fine-tune pre-trained models on custom tasks",
                    "Hands-on: Fine-tune ResNet/EfficientNet on domain-specific dataset"
                ]
            },
            {
                "week": "7",
                "title": "RNNs & LSTMs",
                "duration": "10 hours",
                "topics": [
                    "Sequence modeling: Time series, text, speech",
                    "RNN, LSTM, GRU: Implement in TensorFlow/Keras",
                    "Hands-on: Predict stock prices or generate text with LSTMs"
                ]
            },
            {
                "week": "8",
                "title": "Transformers & Attention Mechanisms",
                "duration": "10 hours",
                "topics": [
                    "Self-attention: Query, key, value, multi-head attention",
                    "Encoder-decoder: BERT, GPT, T5 architectures",
                    "Hugging Face Transformers: Load, fine-tune, deploy",
                    "Hands-on: Fine-tune BERT for text classification, use GPT for generation"
                ]
            },
            {
                "week": "9",
                "title": "Generative Models",
                "duration": "10 hours",
                "topics": [
                    "Autoencoders: Compression, denoising",
                    "VAEs: Latent space, generation",
                    "GANs: Generator, discriminator, training dynamics",
                    "Hands-on: Generate images with VAE/GAN, visualize latent space"
                ]
            },
            {
                "week": "10",
                "title": "Computer Vision Applications",
                "duration": "10 hours",
                "topics": [
                    "Object detection: YOLO, SSD—real-time, efficient",
                    "Image segmentation: U-Net, Mask R-CNN—pixel-level classification",
                    "Hands-on: Detect objects in images, segment medical scans"
                ]
            },
            {
                "week": "11",
                "title": "NLP Applications with Deep Learning",
                "duration": "10 hours",
                "topics": [
                    "Fine-tuning LLMs: Adapt BERT, GPT for custom tasks",
                    "Sequence-to-sequence: Machine translation, text summarization",
                    "Hands-on: Build a translator or chatbot with transformers"
                ]
            },
            {
                "week": "12",
                "title": "Model Optimization & Deployment",
                "duration": "10 hours",
                "topics": [
                    "Quantization: Reduce model size, accelerate inference",
                    "Pruning: Remove unimportant weights",
                    "ONNX: Export for cross-framework deployment",
                    "TensorFlow Serving/TorchServe: Scalable model serving",
                    "Hands-on: Quantize/prune a model, serve via API"
                ]
            },
            {
                "week": "13",
                "title": "Monitoring, Explainability & Ethics",
                "duration": "10 hours",
                "topics": [
                    "Monitoring: Track latency, throughput, drift",
                    "Explainability: SHAP, LIME—interpret model decisions",
                    "Ethics: Bias detection, fairness metrics, mitigation strategies",
                    "Hands-on: Instrument a live model, generate explanations, audit for bias"
                ]
            },
            {
                "week": "14",
                "title": "Capstone & Final Assessment",
                "duration": "10 hours",
                "topics": [
                    "End-to-end DL project: Data → model → evaluation → deployment → monitoring",
                    "Technical quality, scalability, ethics, communication assessment",
                    "Portfolio presentation and project showcase"
                ]
            }
        ],
        "projects": [
            {
                "title": "Real-time Traffic Sign Detection",
                "description": "Build an autonomous vehicle-ready traffic sign detection system using YOLO/EfficientDet for real-time performance",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "OpenCV",
                    "YOLO"
                ],
                "image": "https://images.pexels.com/photos/164634/pexels-photo-164634.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "AI-Powered Medical Imaging Diagnosis",
                "description": "Detect anomalies in X-rays and MRI scans using CNNs and transformers for healthcare applications",
                "technologies": [
                    "TensorFlow",
                    "Keras",
                    "OpenCV",
                    "Transformers"
                ],
                "image": "https://images.pexels.com/photos/4225882/pexels-photo-4225882.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "GAN-based Image-to-Image Translation",
                "description": "Create style transfer applications including sketch→photo, day→night transformations using advanced GANs",
                "technologies": [
                    "PyTorch",
                    "GANs",
                    "OpenCV",
                    "NumPy"
                ],
                "image": "https://images.pexels.com/photos/3860804/pexels-photo-3860804.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Build, train, and evaluate deep neural networks from scratch and using frameworks",
            "Implement CNNs, RNNs, LSTMs, transformers, and GANs for real-world applications",
            "Optimize models for performance and scalability in production environments",
            "Deploy deep learning models to production with monitoring and maintenance",
            "Apply DL to NLP, computer vision, and generative AI use cases",
            "Master state-of-the-art architectures and transfer learning techniques",
            "Understand ethics, explainability, and responsible AI development",
            "Build a portfolio of production-ready deep learning projects"
        ],
        "prerequisites": [
            "Strong Python programming skills",
            "Linear algebra and calculus fundamentals",
            "Basic machine learning knowledge",
            "Experience with NumPy and Pandas",
            "Understanding of statistics and probability"
        ],
        "courseOutcomes": [
            "Expertise in building and deploying deep learning models for production",
            "Portfolio of 3+ advanced AI projects demonstrating real-world applications",
            "Proficiency with industry-standard frameworks (TensorFlow, PyTorch)",
            "Understanding of model optimization and deployment strategies",
            "Knowledge of responsible AI practices and ethical considerations",
            "Preparation for senior AI engineer and ML researcher roles",
            "Ability to architect and scale deep learning systems",
            "Skills in model monitoring, explainability, and continuous improvement"
        ],
        "toolsAndResources": {
            "platform": "Jupyter Notebook, Google Colab, VS Code",
            "libraries": [
                "TensorFlow",
                "Keras",
                "PyTorch",
                "Hugging Face Transformers",
                "OpenCV",
                "scikit-learn",
                "SHAP",
                "LIME"
            ],
            "dataSources": [
                "ImageNet",
                "COCO Dataset",
                "Hugging Face Datasets",
                "Kaggle Competitions"
            ],
            "versionControl": "Git, MLflow, Weights & Biases for experiment tracking",
            "assessment": [
                "Weekly hands-on labs",
                "Model implementation assignments",
                "Capstone project with deployment",
                "Technical presentation"
            ]
        }
    },
    "ai-engineer-career-track": {
        "title": "AI Engineer Career Track",
        "description": "Comprehensive career path: Starter + AI Fundamentals + AI Engineer Pro + Deep Learning",
        "duration": "16-18 weeks",
        "level": "Career Track",
        "mode": "Online/Offline",
        "price": "₹38,000",
        "originalPrice": "₹55,000",
        "rating": 4.9,
        "students": 52,
        "nextBatch": "September 1, 2025",
        "category": "Career Track",
        "color": "from-violet-600 to-purple-600",
        "icon": "<Cpu className=\"w-8 h-8\" />",
        "image": "https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Full Stack AI Engineering",
            "Advanced AI"
        ],
        "mentor": {
            "name": "Rahul Agarwal",
            "role": "AI Engineering Director",
            "company": "L&T Infotech",
            "image": "https://images.pexels.com/photos/1239291/pexels-photo-1239291.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "18+ years in AI engineering and autonomous systems"
        },
        "curriculum": [
            {
                "week": "1-4",
                "title": "AI Foundations & Python Mastery",
                "topics": [
                    "Python advanced",
                    "Math for AI",
                    "ML fundamentals"
                ]
            },
            {
                "week": "5-8",
                "title": "Machine Learning Engineering",
                "topics": [
                    "ML pipelines",
                    "Model optimization",
                    "Feature engineering"
                ]
            },
            {
                "week": "9-12",
                "title": "Deep Learning & Neural Networks",
                "topics": [
                    "CNNs, RNNs",
                    "Transformers",
                    "Advanced architectures"
                ]
            },
            {
                "week": "13-16",
                "title": "AI System Design & Deployment",
                "topics": [
                    "Production AI",
                    "Scalable systems",
                    "MLOps"
                ]
            },
            {
                "week": "17-18",
                "title": "Capstone & Career Preparation",
                "topics": [
                    "Portfolio project",
                    "Interview prep",
                    "Industry networking"
                ]
            }
        ],
        "projects": [
            {
                "title": "End-to-End AI Application",
                "description": "Build and deploy a complete AI-powered application from scratch",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "FastAPI",
                    "Docker",
                    "AWS"
                ],
                "image": "https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ]
    },
    "data-structures-algorithms": {
        "title": "DSA Professional Program — 2025 Edition",
        "description": "Master data structures and algorithms to solve complex computational problems, optimize performance, and excel in coding interviews. Build a strong foundation for technical roles in top companies.",
        "duration": "12 weeks",
        "level": "Intermediate",
        "mode": "Online/Offline",
        "price": "₹15,500",
        "originalPrice": "₹20,000",
        "rating": 4.8,
        "students": 450,
        "nextBatch": "October 15, 2025",
        "category": "Computer Science/Programming",
        "color": "from-purple-500 to-purple-600",
        "icon": "Code",
        "image": "https://images.pexels.com/photos/270348/pexels-photo-270348.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "C++",
            "Java",
            "LeetCode",
            "HackerRank",
            "GitHub"
        ],
        "mentor": {
            "name": "Rahul Sharma",
            "role": "Senior Software Engineer",
            "company": "Google",
            "image": "https://images.pexels.com/photos/2379005/pexels-photo-2379005.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "10+ years in competitive programming and interview coaching"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Introduction to DSA",
                "duration": "10 hours",
                "topics": [
                    "Big O, Big Θ, Big Ω notation",
                    "Problem-solving strategies",
                    "Pseudocode and coding standards",
                    "Hands-on complexity analysis"
                ]
            },
            {
                "week": "2",
                "title": "Arrays & Strings",
                "duration": "10 hours",
                "topics": [
                    "Array operations (insert/delete/search)",
                    "Sliding window technique",
                    "String manipulation (palindromes, anagrams)",
                    "In-place algorithms"
                ]
            },
            {
                "week": "3",
                "title": "Linked Lists",
                "duration": "10 hours",
                "topics": [
                    "Singly/doubly/circular linked lists",
                    "Cycle detection (Floyd's algorithm)",
                    "Merge two sorted lists",
                    "Pointer manipulation"
                ]
            },
            {
                "week": "4",
                "title": "Stacks & Queues",
                "duration": "10 hours",
                "topics": [
                    "Infix-to-postfix conversion",
                    "Priority queues and heaps",
                    "Deque applications",
                    "Stack-based calculator"
                ]
            },
            {
                "week": "5",
                "title": "Recursion & Backtracking",
                "duration": "10 hours",
                "topics": [
                    "Tail vs. head recursion",
                    "N-Queens problem",
                    "Subsets and permutations",
                    "Sudoku solver"
                ]
            },
            {
                "week": "6",
                "title": "Trees",
                "duration": "10 hours",
                "topics": [
                    "BST operations",
                    "Tree traversals (DFS/BFS)",
                    "Heap sort",
                    "AVL tree rotations"
                ]
            },
            {
                "week": "7",
                "title": "Graphs",
                "duration": "10 hours",
                "topics": [
                    "BFS/DFS implementations",
                    "Dijkstra's shortest path",
                    "Union-Find data structure",
                    "Topological sorting"
                ]
            },
            {
                "week": "8",
                "title": "Searching & Sorting",
                "duration": "10 hours",
                "topics": [
                    "Quicksort vs. mergesort",
                    "Non-comparison sorts",
                    "Binary search variations",
                    "Optimization tradeoffs"
                ]
            },
            {
                "week": "9",
                "title": "Hashing & Advanced DS",
                "duration": "10 hours",
                "topics": [
                    "Hash collision handling",
                    "Trie for autocomplete",
                    "Disjoint set applications",
                    "Bloom filters"
                ]
            },
            {
                "week": "10",
                "title": "Dynamic Programming",
                "duration": "10 hours",
                "topics": [
                    "0/1 Knapsack problem",
                    "Longest Increasing Subsequence",
                    "Memoization vs. tabulation",
                    "Space optimization"
                ]
            },
            {
                "week": "11",
                "title": "Problem Solving & Mock Interviews",
                "duration": "10 hours",
                "topics": [
                    "LeetCode pattern recognition",
                    "Whiteboarding practice",
                    "Time complexity analysis",
                    "FAANG interview simulation"
                ]
            },
            {
                "week": "12",
                "title": "Capstone & Final Assessment",
                "duration": "10 hours",
                "topics": [
                    "End-to-end project implementation",
                    "Performance optimization",
                    "Code review and documentation",
                    "Portfolio presentation"
                ]
            }
        ],
        "projects": [
            {
                "title": "Library Management System",
                "description": "Implement catalog search (hash/trie), reservation queues, and recommendation graphs",
                "technologies": [
                    "Python",
                    "Trie",
                    "Priority Queue",
                    "Graphs"
                ],
                "image": "https://images.pexels.com/photos/159775/library-la-trobe-study-students-159775.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Route Optimization Tool",
                "description": "Use Dijkstra/A* for shortest path calculations with visualization",
                "technologies": [
                    "C++",
                    "Graphs",
                    "Dijkstra",
                    "A*"
                ],
                "image": "https://images.pexels.com/photos/235615/pexels-photo-235615.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Autocomplete Search Engine",
                "description": "Build a trie-based prefix search system with ranking",
                "technologies": [
                    "Java",
                    "Trie",
                    "Hashing",
                    "Sorting"
                ],
                "image": "https://images.pexels.com/photos/267350/pexels-photo-267350.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Implement core data structures from scratch",
            "Solve problems using optimal algorithms",
            "Master time/space complexity analysis",
            "Develop interview-ready problem-solving skills",
            "Translate real-world problems into efficient code"
        ],
        "prerequisites": [
            "Basic programming knowledge (Python/C++/Java)",
            "Understanding of loops and functions",
            "High school math (logarithms, combinatorics)"
        ],
        "courseOutcomes": [
            "300+ LeetCode/HackerRank problems solved",
            "Portfolio of 3 DSA projects",
            "FAANG-level interview preparation",
            "Competitive programming foundation",
            "Optimized coding mindset"
        ],
        "toolsAndResources": {
            "platform": "VS Code, LeetCode, HackerRank",
            "libraries": [
                "STL (C++)",
                "Collections (Java)",
                "Algorithms (Python)"
            ],
            "practicePlatforms": [
                "Codeforces",
                "AtCoder",
                "CodeChef"
            ],
            "versionControl": "GitHub for project collaboration",
            "assessment": [
                "Weekly coding challenges",
                "Algorithmic efficiency tests",
                "Mock technical interviews",
                "Capstone project review"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "Complexity analysis of sorting algorithms",
                    "Pseudocode to implementation conversion",
                    "Edge case identification drills"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "Sliding window maximum problems",
                    "In-place array operations",
                    "String encoding/decoding"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Linked list cycle detection",
                    "Merge K sorted lists",
                    "LRU cache implementation"
                ]
            }
        ],
        "assessmentCriteria": {
            "codeQuality": "Readability, modularity, comments",
            "efficiency": "Optimal time/space complexity",
            "problemSolving": "Approach clarity, edge cases",
            "interviewReadiness": "Communication, whiteboarding"
        },
        "industryTrends": {
            "2025Trends": [
                "Increased focus on space complexity",
                "DP problems in ML system design",
                "Graph algorithms for network optimization",
                "Concurrent DSA for distributed systems"
            ],
            "jobMarketDemand": [
                "Software Development Engineers",
                "Quantitative Researchers",
                "Competitive Programmers",
                "System Design Architects"
            ]
        }
    },
    "machine-learning-professional-program": {
        "title": "Machine Learning Professional Program",
        "description": "Train students to build and deploy ML models for structured/unstructured data with production-grade quality.",
        "duration": "10 weeks",
        "level": "Intermediate",
        "mode": "Online/Offline",
        "price": "₹15,500",
        "originalPrice": "₹22,000",
        "rating": 4.8,
        "students": 167,
        "nextBatch": "September 1, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-indigo-500 to-indigo-600",
        "icon": "<Brain className=\"w-8 h-8\" />",
        "image": "https://images.pexels.com/photos/8386553/pexels-photo-8386553.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "Scikit-learn",
            "XGBoost",
            "LightGBM",
            "MLflow",
            "Docker",
            "Flask/FastAPI"
        ],
        "mentor": {
            "name": "Dr. Anjali Rao",
            "role": "ML Engineering Manager",
            "company": "Mindtree",
            "image": "https://images.pexels.com/photos/1239291/pexels-photo-1239291.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "12+ years in machine learning engineering"
        },
        "curriculum": [
            {
                "week": "1-2",
                "title": "Advanced Feature Engineering",
                "topics": [
                    "Feature selection",
                    "Encoding techniques",
                    "Feature scaling"
                ]
            },
            {
                "week": "3-4",
                "title": "Model Selection & Tuning",
                "topics": [
                    "Hyperparameter optimization",
                    "Cross-validation",
                    "Ensemble methods"
                ]
            },
            {
                "week": "5-6",
                "title": "Model Deployment",
                "topics": [
                    "API development",
                    "Containerization",
                    "Model serving"
                ]
            },
            {
                "week": "7-8",
                "title": "ML Pipelines",
                "topics": [
                    "MLflow tracking",
                    "Reproducibility",
                    "Workflow automation"
                ]
            },
            {
                "week": "9-10",
                "title": "Production ML Systems",
                "topics": [
                    "Monitoring",
                    "Retraining",
                    "A/B testing"
                ]
            }
        ],
        "projects": [
            {
                "title": "End-to-End ML Pipeline",
                "description": "Build a complete ML system from data collection to model deployment",
                "technologies": [
                    "Python",
                    "Scikit-learn",
                    "MLflow",
                    "Docker"
                ],
                "image": "https://images.pexels.com/photos/8386553/pexels-photo-8386553.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ]
    },
    "ai-engineer-professional-program": {
        "title": "AI Engineer Professional Program — 2025 Edition",
        "description": "Master AI engineering with hands-on experience in deep learning, computer vision, NLP, and deployment. Build production-ready AI applications using cutting-edge frameworks and cloud platforms.",
        "duration": "12 weeks (144 hours)",
        "level": "Professional",
        "mode": "Online/Offline",
        "price": "₹52,000",
        "originalPrice": "₹75,000",
        "rating": 4.9,
        "students": 142,
        "nextBatch": "October 1, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-blue-500 to-indigo-600",
        "icon": "Cpu",
        "image": "https://images.pexels.com/photos/3861969/pexels-photo-3861969.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "Hugging Face Transformers",
            "OpenCV",
            "FastAPI",
            "LangChain",
            "Scikit-learn",
            "Pandas",
            "NumPy",
            "Matplotlib",
            "Docker",
            "GitHub"
        ],
        "mentor": {
            "name": "Dr. Kavitha Reddy",
            "role": "Senior AI Architect",
            "company": "NVIDIA India",
            "image": "https://images.pexels.com/photos/774909/pexels-photo-774909.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "15+ years in AI research and enterprise AI system development"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "AI Fundamentals & Project Setup",
                "duration": "12 hours",
                "topics": [
                    "AI landscape overview: history, current state, industry applications across sectors",
                    "AI development environment: Python 3.10+, PyTorch 2.x, TensorFlow 2.x, CUDA setup",
                    "JupyterLab configuration and GPU acceleration setup for optimal performance",
                    "Dataset exploration: Kaggle, Hugging Face datasets, government open data",
                    "AI development lifecycle: data collection → model building → training → testing → deployment → monitoring",
                    "Hands-on: Environment setup, dataset exploration, and project planning"
                ]
            },
            {
                "week": "2",
                "title": "Data Handling for AI",
                "duration": "12 hours",
                "topics": [
                    "Large-scale data processing: efficient disk I/O, database connections, streaming data sources",
                    "Multimodal preprocessing: text tokenization and cleaning, image scaling and augmentation",
                    "Audio data processing: normalization, spectrograms, and feature extraction",
                    "Advanced feature engineering: domain-specific transforms, handling class imbalance",
                    "Time-series data processing and preparation techniques",
                    "Hands-on: Preprocess mixed datasets (text + images + audio), benchmark with Dask/Polars"
                ]
            },
            {
                "week": "3",
                "title": "Machine Learning Review",
                "duration": "12 hours",
                "topics": [
                    "Supervised learning: regression, classification with advanced techniques",
                    "Unsupervised learning: clustering, dimensionality reduction, association rules",
                    "Feature engineering: domain-specific transforms, encoding strategies, scaling methods",
                    "Model selection and evaluation: cross-validation, metrics, hyperparameter tuning",
                    "When to use classic ML vs. deep learning approaches",
                    "Hands-on: Build and optimize complete ML pipeline on real dataset"
                ]
            },
            {
                "week": "4",
                "title": "Deep Learning Fundamentals",
                "duration": "12 hours",
                "topics": [
                    "Neural network architecture: perceptrons, activation functions, backpropagation theory",
                    "PyTorch and TensorFlow frameworks: eager vs. graph execution, GPU acceleration",
                    "Training optimization: loss functions, optimizers, learning rate scheduling",
                    "Model evaluation: comprehensive metrics, confusion matrices, learning curve analysis",
                    "Debugging neural networks: vanishing gradients, overfitting, convergence issues",
                    "Hands-on: Train, validate, and interpret neural networks on Kaggle datasets"
                ]
            },
            {
                "week": "5",
                "title": "Computer Vision Applications",
                "duration": "12 hours",
                "topics": [
                    "Image classification: from scratch implementation and transfer learning",
                    "Object detection fundamentals: YOLO, Faster R-CNN architectures",
                    "Pretrained models: ResNet, EfficientNet, Vision Transformers (ViT)",
                    "Custom dataset preparation and annotation for computer vision tasks",
                    "Model fine-tuning and optimization for specific domains",
                    "Hands-on: Fine-tune CNN on custom image dataset, deploy as REST API"
                ]
            },
            {
                "week": "6",
                "title": "NLP Foundations",
                "duration": "12 hours",
                "topics": [
                    "Text preprocessing: tokenization methods (WordPiece, SentencePiece, subword)",
                    "Word embeddings: Word2Vec, GloVe, FastText, and contextual embeddings",
                    "Transformer architecture: attention mechanisms, encoder/decoder, BERT/GPT basics",
                    "NLP tasks: sentiment analysis, text classification, named entity recognition",
                    "Evaluation metrics for NLP: BLEU, ROUGE, perplexity, F1 scores",
                    "Hands-on: Build and evaluate sentiment analysis and text classification models"
                ]
            },
            {
                "week": "7",
                "title": "Advanced NLP with Hugging Face",
                "duration": "12 hours",
                "topics": [
                    "Pretrained models: BERT, RoBERTa, GPT-3, T5, multilingual model selection",
                    "Model fine-tuning: adapting models to domain tasks, parameter-efficient tuning (LoRA)",
                    "Prompt engineering: zero-shot, few-shot learning, chain-of-thought prompting",
                    "Hugging Face ecosystem: datasets, tokenizers, trainers, model hub",
                    "Advanced techniques: knowledge distillation, model compression",
                    "Hands-on: Fine-tune transformer on custom task, optimize prompts for quality"
                ]
            },
            {
                "week": "8",
                "title": "Speech & Audio AI",
                "duration": "12 hours",
                "topics": [
                    "Speech recognition: Whisper, Wav2Vec, CTC/Transformer architectures",
                    "Audio classification: environmental sound, speaker identification, emotion detection",
                    "Audio preprocessing: feature extraction, MFCC, spectrograms, mel-spectrograms",
                    "Open-source tools: Librosa, torchaudio, ESPnet frameworks",
                    "Real-time audio processing and streaming applications",
                    "Hands-on: Build speech recognition and audio classification pipelines"
                ]
            },
            {
                "week": "9",
                "title": "Model Deployment",
                "duration": "12 hours",
                "topics": [
                    "Model serialization: ONNX, TorchScript, TensorFlow SavedModel formats",
                    "API development: FastAPI and Flask for model serving with Swagger documentation",
                    "Containerization: Docker for reproducibility, Kubernetes for scaling",
                    "Performance optimization: model quantization, pruning, distillation",
                    "Monitoring and logging: tracking model performance and system health",
                    "Hands-on: Containerize and deploy AI model as scalable REST API"
                ]
            },
            {
                "week": "10",
                "title": "AI in the Cloud",
                "duration": "12 hours",
                "topics": [
                    "Cloud platforms: AWS SageMaker, Azure ML, GCP Vertex AI comparison",
                    "Managed services: automated training, hosting, and AutoML capabilities",
                    "Scaling strategies: spot/preemptible instances, auto-scaling, distributed training",
                    "Cost optimization: monitoring usage, rightsizing resources, serverless inference",
                    "Multi-cloud deployment strategies and vendor lock-in avoidance",
                    "Hands-on: Train and deploy model on cloud platforms, compare costs and performance"
                ]
            },
            {
                "week": "11",
                "title": "Real-World AI Project",
                "duration": "12 hours",
                "topics": [
                    "Project scoping: industry dataset selection (medical imaging, transaction analysis)",
                    "End-to-end pipeline: data preparation → modeling → evaluation → deployment → monitoring",
                    "Testing strategies: unit tests, integration tests, load testing, bias testing",
                    "Documentation: technical specifications, user guides, API documentation",
                    "Team collaboration: version control, code reviews, agile methodology",
                    "Hands-on: Deliver production-grade AI solution with comprehensive documentation"
                ]
            },
            {
                "week": "12",
                "title": "Capstone Project Presentation",
                "duration": "12 hours",
                "topics": [
                    "Project presentation: technical methodology, results analysis, business impact",
                    "Peer review: code quality assessment, architecture feedback, bias analysis",
                    "Portfolio development: GitHub showcase, demo videos, live API demonstrations",
                    "Job preparation: resume optimization, interview practice, technical question prep",
                    "Industry networking: LinkedIn optimization, professional portfolio building",
                    "Ethics and fairness: responsible AI practices, bias detection, regulatory compliance"
                ]
            }
        ],
        "projects": [
            {
                "title": "AI-Powered Customer Support Chatbot",
                "description": "Build an intelligent chatbot integrating LLMs with sentiment analysis for real-time customer assistance and support automation",
                "technologies": [
                    "Python",
                    "Hugging Face Transformers",
                    "FastAPI",
                    "LangChain"
                ],
                "image": "https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Real-Time Object Detection System",
                "description": "Deploy YOLO or EfficientDet for surveillance, retail analytics, or industrial quality control with real-time processing",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "OpenCV",
                    "Docker"
                ],
                "image": "https://images.pexels.com/photos/2599244/pexels-photo-2599244.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Document Processing & Classification",
                "description": "Automate legal, medical, or business document processing with advanced NLP techniques and classification",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "Hugging Face",
                    "FastAPI"
                ],
                "image": "https://images.pexels.com/photos/1181675/pexels-photo-1181675.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Speech Recognition & Analysis",
                "description": "Build comprehensive speech-to-text system with emotion detection and speaker identification capabilities",
                "technologies": [
                    "Python",
                    "Whisper",
                    "PyTorch",
                    "Librosa"
                ],
                "image": "https://images.pexels.com/photos/7516337/pexels-photo-7516337.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master deep learning frameworks (PyTorch, TensorFlow) for production-ready applications",
            "Develop expertise in computer vision applications using CNNs and transfer learning",
            "Build advanced NLP systems using transformers and Hugging Face ecosystem",
            "Implement speech and audio AI solutions for real-world applications",
            "Deploy scalable AI models using cloud platforms and containerization",
            "Create end-to-end AI workflows from data to production deployment",
            "Apply MLOps principles for sustainable and maintainable AI systems",
            "Understand ethical AI practices and bias detection in AI systems"
        ],
        "prerequisites": [
            "Strong Python programming skills with object-oriented concepts",
            "Basic machine learning knowledge (supervised/unsupervised learning)",
            "Familiarity with data manipulation using Pandas and NumPy",
            "Understanding of linear algebra and statistics fundamentals",
            "Experience with Jupyter notebooks and data analysis workflows",
            "Basic knowledge of deep learning concepts is helpful"
        ],
        "courseOutcomes": [
            "Senior AI Engineer with expertise in multiple AI domains",
            "Professional portfolio showcasing deployed AI applications",
            "Proficiency in computer vision, NLP, and speech processing",
            "Cloud deployment expertise with major platforms (AWS, Azure, GCP)",
            "Understanding of MLOps and production AI system management",
            "Preparation for AI architect and principal engineer roles",
            "Knowledge of responsible AI and ethical considerations",
            "Industry network and career advancement opportunities"
        ],
        "toolsAndResources": {
            "platform": "JupyterLab, Google Colab Pro, Kaggle Kernels, AWS SageMaker",
            "libraries": [
                "PyTorch",
                "TensorFlow",
                "Hugging Face Transformers",
                "OpenCV",
                "LangChain",
                "Scikit-learn",
                "Librosa",
                "torchaudio"
            ],
            "cloud": [
                "AWS SageMaker",
                "Google Cloud Vertex AI",
                "Azure Machine Learning",
                "NVIDIA DGX Cloud"
            ],
            "deployment": [
                "FastAPI",
                "Docker",
                "Kubernetes",
                "MLflow",
                "GitHub Actions"
            ],
            "versionControl": "Git, GitHub, GitLab with MLOps workflows",
            "automation": "MLflow, Weights & Biases, DVC for experiment tracking",
            "assessment": [
                "Weekly hands-on projects",
                "Algorithm implementation challenges",
                "Mid-term AI application development",
                "Final capstone project with deployment"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "AI development environment setup with GPU acceleration",
                    "Dataset exploration and project planning workshop",
                    "AI lifecycle implementation on sample problems"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "Multimodal data preprocessing pipeline development",
                    "Large-scale data handling with Dask and Polars",
                    "Feature engineering for different data types"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Complete ML pipeline implementation and optimization",
                    "Classic ML vs deep learning decision framework",
                    "Real-world dataset analysis and model selection"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Neural network training with PyTorch and TensorFlow",
                    "Debugging and optimization of deep learning models",
                    "Comprehensive model evaluation and interpretation"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Computer vision model fine-tuning and deployment",
                    "Custom object detection system development",
                    "Transfer learning implementation across domains"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalProficiency": "Mastery of AI frameworks and implementation of complex algorithms",
            "systemDesign": "Ability to architect and build scalable AI applications",
            "deploymentSkills": "Production deployment experience with cloud platforms",
            "codeQuality": "Clean, efficient, and well-documented code with proper testing",
            "domainExpertise": "Deep understanding of computer vision, NLP, and speech processing",
            "industryReadiness": "MLOps knowledge, ethics awareness, and communication skills"
        }
    },
    "gen-ai-engineer-professional-program": {
        "title": "Generative AI Engineer Professional Program — 2025 Edition",
        "description": "Master generative AI with hands-on experience in LLMs, diffusion models, multimodal AI, and deployment. Build cutting-edge applications using foundation models, prompt engineering, and AI agents.",
        "duration": "12 weeks (144 hours)",
        "level": "Professional",
        "mode": "Online/Offline",
        "price": "₹55,000",
        "originalPrice": "₹80,000",
        "rating": 4.9,
        "students": 167,
        "nextBatch": "October 15, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-purple-500 to-pink-600",
        "icon": "Sparkles",
        "image": "https://images.pexels.com/photos/8386434/pexels-photo-8386434.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "Hugging Face Transformers",
            "LangChain",
            "OpenAI API",
            "Stable Diffusion",
            "DALL·E",
            "Weaviate",
            "Pinecone",
            "FastAPI",
            "Docker",
            "Streamlit"
        ],
        "mentor": {
            "name": "Rajesh Kumar",
            "role": "Principal GenAI Engineer",
            "company": "OpenAI India",
            "image": "https://images.pexels.com/photos/774909/pexels-photo-774909.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "12+ years in AI research with focus on generative models and LLM applications"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "Introduction to Generative AI",
                "duration": "12 hours",
                "topics": [
                    "Generative AI landscape: current trends, foundation models, and industry impact",
                    "Core architectures: LLMs (GPT, Claude), GANs, diffusion models overview",
                    "Development environment: Python 3.10+, CUDA, PyTorch 2.x, JupyterLab setup",
                    "Hugging Face ecosystem: transformers, diffusers, datasets libraries",
                    "Industry applications across sectors: content creation, automation, personalization",
                    "Hands-on: Explore text, image, and code generation using open-source models"
                ]
            },
            {
                "week": "2",
                "title": "Foundation Models & APIs",
                "duration": "12 hours",
                "topics": [
                    "Commercial LLMs: GPT-4, Claude, Gemini - strengths, costs, and licensing",
                    "Open-source models: LLaMA, Mistral, Code Llama comparison and selection",
                    "API integration: OpenAI, Anthropic, Google AI authentication and usage",
                    "Model registry: Hugging Face Hub exploration, model discovery and comparison",
                    "Cost optimization: balancing performance, latency, and expenses",
                    "Hands-on: Generate text, chat, and summaries using various APIs and local models"
                ]
            },
            {
                "week": "3",
                "title": "Prompt Engineering",
                "duration": "12 hours",
                "topics": [
                    "Prompt design principles: clear instructions, system/user roles, structured output",
                    "Advanced techniques: zero-shot, few-shot, chain-of-thought, tree-of-thought",
                    "Constitutional AI: safety, helpfulness, and harmlessness in prompts",
                    "Evaluation frameworks: metrics for prompt quality, bias detection, safety",
                    "Template engineering: dynamic prompts, variable injection, conversation flow",
                    "Hands-on: Optimize prompts for summarization, Q&A, and creative writing tasks"
                ]
            },
            {
                "week": "4",
                "title": "Fine-tuning LLMs",
                "duration": "12 hours",
                "topics": [
                    "Dataset preparation: collection, cleaning, formatting for domain-specific tasks",
                    "Parameter-efficient fine-tuning: LoRA, PEFT, QLoRA for cost-effective training",
                    "Training infrastructure: distributed training, GPU optimization, memory management",
                    "Evaluation metrics: beyond accuracy - robustness, bias, safety, hallucination detection",
                    "Model deployment: serving fine-tuned models locally and via cloud APIs",
                    "Hands-on: Fine-tune LLaMA or Mistral for custom domain tasks with deployment"
                ]
            },
            {
                "week": "5",
                "title": "Image Generation Models",
                "duration": "12 hours",
                "topics": [
                    "Diffusion models: Stable Diffusion, DALL·E architecture and implementation",
                    "Custom generation: Dreambooth, textual inversion, LoRA for style adaptation",
                    "Advanced control: ControlNet for pose/structure guidance, inpainting, outpainting",
                    "Fine-tuning workflows: dataset preparation, training loops, evaluation metrics",
                    "Commercial APIs: Midjourney, DALL·E integration and cost comparison",
                    "Hands-on: Generate and customize images, fine-tune models on custom datasets"
                ]
            },
            {
                "week": "6",
                "title": "Multimodal AI",
                "duration": "12 hours",
                "topics": [
                    "Vision-language models: CLIP, BLIP, LLaVA for image understanding and generation",
                    "Speech integration: Whisper for speech-to-text, TTS for text-to-speech",
                    "Multimodal workflows: combining text, image, audio in unified applications",
                    "Cross-modal generation: text-to-image-to-text, audio-visual synchronization",
                    "Application development: travel assistants, content creation platforms",
                    "Hands-on: Build multimodal travel assistant with image analysis and audio guides"
                ]
            },
            {
                "week": "7",
                "title": "GenAI for Code & Automation",
                "duration": "12 hours",
                "topics": [
                    "Code generation models: Codex, Code LLaMA, StarCoder capabilities and limitations",
                    "Code quality assessment: correctness, security, performance benchmarking",
                    "Automation workflows: GitHub Copilot integration, CI/CD pipeline enhancement",
                    "Infrastructure as code: automated deployment scripts, configuration generation",
                    "Code explanation and refactoring: legacy code modernization, documentation",
                    "Hands-on: Build Copilot-like tools, integrate AI into development workflows"
                ]
            },
            {
                "week": "8",
                "title": "LangChain & Vector Databases",
                "duration": "12 hours",
                "topics": [
                    "LangChain framework: chains, agents, memory management for complex workflows",
                    "Vector databases: Pinecone, Weaviate, FAISS for semantic search and retrieval",
                    "Embedding strategies: text, image, multimodal embeddings for similarity search",
                    "RAG implementation: Retrieval-Augmented Generation for knowledge-grounded responses",
                    "Performance optimization: indexing strategies, query optimization, caching",
                    "Hands-on: Build comprehensive RAG system for Q&A over large document collections"
                ]
            },
            {
                "week": "9",
                "title": "AI Agents & Tool Integration",
                "duration": "12 hours",
                "topics": [
                    "Agent architectures: ReAct, Plan-and-Execute, Multi-agent systems design",
                    "Tool integration: APIs, databases, web scraping, external service connections",
                    "Orchestration frameworks: LangChain Agents, AutoGPT, LangGraph for workflow management",
                    "Memory and state management: conversation history, context preservation",
                    "Error handling and fallback strategies for robust agent behavior",
                    "Hands-on: Develop AI agent for travel booking, customer support, or data analysis"
                ]
            },
            {
                "week": "10",
                "title": "Deployment & Scaling",
                "duration": "12 hours",
                "topics": [
                    "API development: FastAPI, Streamlit for GenAI application interfaces",
                    "Containerization: Docker for reproducible deployments, Kubernetes orchestration",
                    "Cloud deployment: AWS SageMaker, GCP Vertex AI, Azure OpenAI Service",
                    "Performance optimization: model quantization, caching strategies, load balancing",
                    "Monitoring and observability: logging, metrics, cost tracking, usage analytics",
                    "Hands-on: Deploy GenAI application to cloud with monitoring and auto-scaling"
                ]
            },
            {
                "week": "11",
                "title": "Real-World Project Development",
                "duration": "12 hours",
                "topics": [
                    "Project scoping: industry use case selection and requirements gathering",
                    "End-to-end development: data pipeline → model selection → deployment → monitoring",
                    "Testing strategies: unit tests, integration tests, security testing, bias evaluation",
                    "Documentation: technical specifications, API documentation, user guides",
                    "Collaboration workflows: version control, code review, agile development practices",
                    "Hands-on: Complete production-grade GenAI solution with full documentation"
                ]
            },
            {
                "week": "12",
                "title": "Capstone Project Presentation",
                "duration": "12 hours",
                "topics": [
                    "Live project demonstration: interactive presentation with technical deep-dive",
                    "Peer review sessions: code quality, architecture review, ethical considerations",
                    "Portfolio development: GitHub showcase, demo videos, API documentation",
                    "Career preparation: resume optimization, interview practice, technical presentations",
                    "Industry networking: LinkedIn optimization, professional portfolio building",
                    "Ethics and responsibility: bias detection, safety measures, regulatory compliance"
                ]
            }
        ],
        "projects": [
            {
                "title": "AI-Powered Design Assistant",
                "description": "Generate UI/UX mockups from text descriptions and user feedback using multimodal AI and design principles",
                "technologies": [
                    "Python",
                    "Stable Diffusion",
                    "LangChain",
                    "Streamlit"
                ],
                "image": "https://images.pexels.com/photos/196644/pexels-photo-196644.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Multimodal Marketing Studio",
                "description": "Create comprehensive marketing content including social posts, ads, and multimedia clips from product images and prompts",
                "technologies": [
                    "Python",
                    "DALL·E",
                    "GPT-4",
                    "FastAPI"
                ],
                "image": "https://images.pexels.com/photos/267350/pexels-photo-267350.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "AI Content Generation Platform",
                "description": "Automate article writing, social media posts, and graphic generation at scale for media companies",
                "technologies": [
                    "Python",
                    "OpenAI API",
                    "Weaviate",
                    "Docker"
                ],
                "image": "https://images.pexels.com/photos/261662/pexels-photo-261662.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Intelligent Code Assistant",
                "description": "Build advanced code generation, explanation, and refactoring tool with multiple programming language support",
                "technologies": [
                    "Python",
                    "Code Llama",
                    "LangChain",
                    "GitHub API"
                ],
                "image": "https://images.pexels.com/photos/1181263/pexels-photo-1181263.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master foundation models (LLMs, diffusion models) and their applications",
            "Develop expertise in prompt engineering and model fine-tuning techniques",
            "Build multimodal AI applications combining text, image, and audio",
            "Implement advanced RAG systems and AI agents for complex workflows",
            "Deploy scalable generative AI applications using modern cloud platforms",
            "Create production-ready GenAI solutions with proper monitoring and optimization",
            "Apply ethical AI principles and bias detection in generative systems",
            "Understand the business impact and ROI of generative AI implementations"
        ],
        "prerequisites": [
            "Strong Python programming skills with API development experience",
            "Basic understanding of machine learning and deep learning concepts",
            "Familiarity with cloud platforms (AWS, Azure, or GCP) preferred",
            "Experience with REST APIs and web development frameworks",
            "Understanding of software development lifecycle and version control",
            "Basic knowledge of natural language processing is helpful"
        ],
        "courseOutcomes": [
            "Senior GenAI Engineer with expertise in foundation models and applications",
            "Professional portfolio showcasing deployed generative AI solutions",
            "Proficiency in LLM fine-tuning, prompt engineering, and multimodal AI",
            "Expertise in AI agents, RAG systems, and workflow orchestration",
            "Cloud deployment skills with optimization and monitoring capabilities",
            "Preparation for GenAI architect and principal engineer positions",
            "Knowledge of responsible AI development and ethical considerations",
            "Industry connections and career advancement opportunities in GenAI"
        ],
        "toolsAndResources": {
            "platform": "JupyterLab, Google Colab Pro, Hugging Face Spaces, Streamlit Cloud",
            "libraries": [
                "Hugging Face Transformers",
                "LangChain",
                "LlamaIndex",
                "Diffusers",
                "OpenAI SDK",
                "Anthropic SDK",
                "Pinecone",
                "Weaviate"
            ],
            "cloud": [
                "AWS Bedrock",
                "Google Cloud Vertex AI",
                "Azure OpenAI Service",
                "Hugging Face Inference Endpoints"
            ],
            "deployment": [
                "FastAPI",
                "Streamlit",
                "Docker",
                "Kubernetes",
                "Vercel",
                "Railway"
            ],
            "versionControl": "Git, GitHub, Hugging Face Hub for model versioning",
            "monitoring": "Weights & Biases, MLflow, LangSmith for experiment tracking",
            "assessment": [
                "Weekly generative AI projects",
                "Prompt engineering challenges",
                "Mid-term multimodal application development",
                "Final capstone project with deployment and presentation"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "GenAI environment setup with GPU optimization",
                    "Foundation model exploration and comparison",
                    "Basic text and image generation workflows"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "API integration with multiple LLM providers",
                    "Cost analysis and optimization strategies",
                    "Local vs cloud model deployment comparison"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Advanced prompt engineering techniques",
                    "Prompt template optimization and evaluation",
                    "Bias detection and mitigation in prompts"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "LLM fine-tuning with LoRA and PEFT",
                    "Custom dataset preparation and validation",
                    "Model evaluation and performance benchmarking"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Custom image generation model training",
                    "Style transfer and ControlNet implementation",
                    "Multimodal content creation pipeline"
                ]
            },
            {
                "week": 6,
                "exercises": [
                    "Multimodal travel assistant development",
                    "Cross-modal generation workflows",
                    "Voice-enabled AI application building"
                ]
            },
            {
                "week": 7,
                "exercises": [
                    "AI-powered code generation tool creation",
                    "GitHub integration and workflow automation",
                    "Code quality assessment system development"
                ]
            },
            {
                "week": 8,
                "exercises": [
                    "Comprehensive RAG system implementation",
                    "Vector database optimization and scaling",
                    "Knowledge retrieval performance tuning"
                ]
            },
            {
                "week": 9,
                "exercises": [
                    "Multi-agent system architecture design",
                    "Tool-using AI agent development",
                    "Workflow orchestration and automation"
                ]
            },
            {
                "week": 10,
                "exercises": [
                    "Cloud deployment with auto-scaling",
                    "Performance monitoring and optimization",
                    "Cost-effective scaling strategies implementation"
                ]
            },
            {
                "week": 11,
                "exercises": [
                    "End-to-end production system development",
                    "Comprehensive testing and validation",
                    "Documentation and deployment automation"
                ]
            },
            {
                "week": 12,
                "exercises": [
                    "Capstone project presentation and demo",
                    "Portfolio optimization and showcase",
                    "Interview preparation and career planning"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalProficiency": "Mastery of generative AI frameworks and implementation of complex models",
            "promptEngineering": "Excellence in prompt design, optimization, and evaluation techniques",
            "multimodalIntegration": "Ability to build and deploy multimodal AI applications effectively",
            "systemArchitecture": "Skills in designing scalable GenAI systems and workflows",
            "deploymentExpertise": "Production deployment experience with cloud platforms and optimization",
            "ethicalConsiderations": "Understanding of responsible AI practices and bias detection",
            "industryReadiness": "Communication skills, portfolio quality, and real-world application development"
        },
        "marketDemand": "Generative AI is one of the fastest-growing fields in AI, powering breakthroughs in art, content generation, code writing, product design, and personalized experiences. Companies are seeking engineers who can harness large language models (LLMs) and generative architectures to create cutting-edge applications.",
        "careerOpportunities": [
            "Senior Generative AI Engineer",
            "GenAI Solutions Architect",
            "LLM Application Developer",
            "Prompt Engineering Specialist",
            "Multimodal AI Developer",
            "AI Product Manager (Technical)",
            "Research Scientist - Generative AI",
            "Principal AI Engineer"
        ],
        "industryApplications": [
            "Content Creation and Media",
            "E-commerce and Marketing",
            "Healthcare and Drug Discovery",
            "Education and Training",
            "Gaming and Entertainment",
            "Financial Services",
            "Legal and Compliance",
            "Software Development and DevOps"
        ]
    },
    "mlops-ai-deployment": {
        "title": "MLOps & AI Deployment Professional Program — 2025 Edition",
        "description": "Master end-to-end MLOps pipelines from model development to production deployment. Learn CI/CD, monitoring, and scaling for enterprise AI systems.",
        "duration": "12 weeks (120+ hours)",
        "level": "Intermediate to Advanced",
        "mode": "Online/Offline",
        "price": "₹22,000",
        "originalPrice": "₹30,000",
        "rating": 4.9,
        "students": 156,
        "nextBatch": "September 8, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-green-500 to-green-600",
        "icon": "Settings",
        "image": "https://images.pexels.com/photos/3861958/pexels-photo-3861958.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "Docker",
            "Kubernetes",
            "Git",
            "GitHub Actions",
            "MLflow",
            "DVC",
            "TensorFlow",
            "PyTorch",
            "FastAPI",
            "AWS/GCP/Azure",
            "Kubeflow"
        ],
        "mentor": {
            "name": "Vikram Patel",
            "role": "Senior MLOps Engineer",
            "company": "Flipkart",
            "image": "https://images.pexels.com/photos/3777931/pexels-photo-3777931.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "10+ years in ML engineering and production systems"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "MLOps Foundations",
                "duration": "10 hours",
                "topics": [
                    "MLOps lifecycle: data, training, deployment, monitoring, retraining",
                    "MLOps vs. DevOps: ML-specific challenges (data drift, model decay)",
                    "Industry trends: GitOps for ML, model registries, reproducibility",
                    "Hands-on: Map a real ML project's lifecycle"
                ]
            },
            {
                "week": "2",
                "title": "Data & Model Versioning",
                "duration": "10 hours",
                "topics": [
                    "Data Version Control (DVC): Track datasets, metrics, artifacts",
                    "Model Versioning (MLflow): Log experiments, register models",
                    "Git Integration: Version control for code, data, and models",
                    "Hands-on: Set up DVC+Git, log experiments with MLflow"
                ]
            },
            {
                "week": "3",
                "title": "Containerization & Environments",
                "duration": "10 hours",
                "topics": [
                    "Docker fundamentals: Images, containers, Dockerfiles for ML",
                    "Environment Management: Conda, Pipenv, Poetry",
                    "Reproducible Builds: Pin libraries, avoid environment issues",
                    "Hands-on: Containerize Python ML app, build and share images"
                ]
            },
            {
                "week": "4",
                "title": "Orchestration & Workflow Management",
                "duration": "10 hours",
                "topics": [
                    "Apache Airflow: DAGs, operators, scheduling, monitoring",
                    "Kubeflow: Kubernetes-native ML pipelines, component reuse",
                    "Scalable Pipelines: Design for parallel training, validation",
                    "Hands-on: Build Airflow DAG for ML training, deploy Kubeflow pipeline"
                ]
            },
            {
                "week": "5",
                "title": "API Deployment for ML Models",
                "duration": "10 hours",
                "topics": [
                    "FastAPI: Async, typed, OpenAPI/Swagger docs, high performance",
                    "REST Endpoints: Predict, health check, versioning",
                    "Model Packaging: ONNX, joblib, pickle, TensorFlow Serving",
                    "Hands-on: Deploy ML model as REST API, test with Postman"
                ]
            },
            {
                "week": "6",
                "title": "Cloud Deployment Strategies",
                "duration": "10 hours",
                "topics": [
                    "AWS SageMaker: Managed training, hosting, AutoML, endpoints",
                    "GCP Vertex AI: Pipelines, custom training, model registry",
                    "Azure ML: Workspaces, experiments, deployment",
                    "Kubernetes: Deploy anywhere, autoscaling, GPU/TPU scheduling",
                    "Hands-on: Train and deploy model on cloud, scale with Kubernetes"
                ]
            },
            {
                "week": "7",
                "title": "CI/CD for Machine Learning",
                "duration": "10 hours",
                "topics": [
                    "GitHub Actions: Trigger on code/data/model changes, run tests",
                    "Continuous Training: Retrain on new data, validate, promote",
                    "Continuous Deployment: Roll out new models, blue-green, canary",
                    "Hands-on: Set up GitHub Actions CI/CD for ML project"
                ]
            },
            {
                "week": "8",
                "title": "Model Monitoring & Logging",
                "duration": "10 hours",
                "topics": [
                    "Performance Tracking: Latency, throughput, error rates",
                    "Data/Model Drift: Detect drift, trigger retraining",
                    "Alerting: Prometheus, Grafana, Slack/email alerts",
                    "Hands-on: Instrument live model with logging and drift detection"
                ]
            },
            {
                "week": "9",
                "title": "Security & Governance",
                "duration": "10 hours",
                "topics": [
                    "API Security: Auth (OAuth, API keys), rate limiting, input validation",
                    "Data Governance: Row-level security, masking, audit logs",
                    "Compliance: GDPR, HIPAA, AI ethics, bias/fairness checks",
                    "Hands-on: Secure ML API, implement compliance checks"
                ]
            },
            {
                "week": "10",
                "title": "Advanced Deployment Patterns",
                "duration": "10 hours",
                "topics": [
                    "Multi-Model Serving: Deploy ensembles, A/B test variants",
                    "Shadow Deployment: Run new model alongside old, compare outputs",
                    "Canary Releases: Gradual rollout, monitor, rollback if needed",
                    "Hands-on: Deploy two model versions, A/B test with traffic splitting"
                ]
            },
            {
                "week": "11",
                "title": "Optimization & Cost Management",
                "duration": "10 hours",
                "topics": [
                    "GPU/TPU Optimization: Mixed precision, quantization, pruning",
                    "Serverless: AWS Lambda, GCP Cloud Functions, Azure Functions",
                    "Cost Tracking: Cloud billing dashboards, spot instances, autoscaling",
                    "Hands-on: Optimize model for inference speed, deploy serverless"
                ]
            },
            {
                "week": "12",
                "title": "Capstone & Final Assessment",
                "duration": "10 hours",
                "topics": [
                    "Full MLOps pipeline: data → train → deploy → monitor → retrain",
                    "Monitoring: Track performance, drift, and costs",
                    "Scaling: Handle production traffic, autoscaling, logging",
                    "Portfolio: GitHub repo with code, docs, and live demo"
                ]
            }
        ],
        "projects": [
            {
                "title": "Fraud Detection Pipeline",
                "description": "Build complete MLOps pipeline for fraud detection: data ingestion, model training, deployment, monitoring, and automated retraining",
                "technologies": [
                    "Python",
                    "MLflow",
                    "Docker",
                    "Kubernetes",
                    "FastAPI"
                ],
                "image": "https://images.pexels.com/photos/4386321/pexels-photo-4386321.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "AI-Powered Recommendation System",
                "description": "Implement continuous retraining pipeline with A/B testing for recommendation algorithms and user engagement monitoring",
                "technologies": [
                    "Python",
                    "Kubeflow",
                    "Prometheus",
                    "Grafana",
                    "AWS"
                ],
                "image": "https://images.pexels.com/photos/3184465/pexels-photo-3184465.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Image Classification on Kubernetes",
                "description": "Deploy CNN model with autoscaling, monitoring accuracy and latency, implementing blue-green deployment strategy",
                "technologies": [
                    "Kubernetes",
                    "TensorFlow",
                    "Docker",
                    "GitHub Actions"
                ],
                "image": "https://images.pexels.com/photos/3861969/pexels-photo-3861969.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Design reproducible ML workflows with version control for data and models",
            "Deploy AI models into scalable production environments",
            "Automate CI/CD pipelines for ML projects with testing and validation",
            "Monitor model performance and implement automated retraining pipelines",
            "Optimize AI systems for cost, performance, and scalability",
            "Implement security and governance best practices for production ML",
            "Master cloud-native deployment strategies and containerization",
            "Build end-to-end MLOps solutions for enterprise environments"
        ],
        "prerequisites": [
            "Python programming proficiency",
            "Basic machine learning knowledge",
            "Understanding of software development lifecycle",
            "Familiarity with command line and version control (Git)",
            "Basic cloud computing concepts"
        ],
        "courseOutcomes": [
            "Expertise in building production-grade MLOps pipelines",
            "Portfolio of deployed, monitored, and scalable ML systems",
            "Proficiency with industry-standard MLOps tools and platforms",
            "Understanding of cloud deployment and cost optimization strategies",
            "Knowledge of ML security, governance, and compliance requirements",
            "Preparation for MLOps Engineer and ML Platform Engineer roles",
            "Skills in automation, monitoring, and continuous improvement",
            "Experience with multi-cloud and hybrid deployment scenarios"
        ],
        "toolsAndResources": {
            "platform": "VS Code, Docker Desktop, Kubernetes",
            "libraries": [
                "MLflow",
                "DVC",
                "FastAPI",
                "Prometheus",
                "Grafana",
                "Airflow",
                "Kubeflow"
            ],
            "dataSources": [
                "Public APIs",
                "Cloud data warehouses",
                "Streaming data sources",
                "Enterprise datasets"
            ],
            "versionControl": "Git, GitHub/GitLab for CI/CD, MLflow for experiments",
            "assessment": [
                "Hands-on pipeline building",
                "Deployment challenges",
                "Monitoring and optimization tasks",
                "Capstone MLOps project"
            ]
        }
    },
    "nlp-chatbot-development": {
        "title": "NLP & Chatbot Development Professional Program — 2025 Edition",
        "description": "Build intelligent chatbots and NLP applications using transformers, LangChain, and LLMs. Master conversational AI for real-world business applications.",
        "duration": "12 weeks (120+ hours)",
        "level": "Intermediate",
        "mode": "Online/Offline",
        "price": "₹20,000",
        "originalPrice": "₹28,000",
        "rating": 4.7,
        "students": 203,
        "nextBatch": "September 22, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-indigo-500 to-indigo-600",
        "icon": "MessageSquare",
        "image": "https://images.pexels.com/photos/3861972/pexels-photo-3861972.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "NLTK",
            "spaCy",
            "Hugging Face Transformers",
            "OpenAI API",
            "Rasa",
            "LangChain",
            "FastAPI",
            "Flask",
            "TensorFlow",
            "PyTorch",
            "Dialogflow",
            "AWS Lex"
        ],
        "mentor": {
            "name": "Priya Nair",
            "role": "Senior NLP Engineer",
            "company": "Swiggy",
            "image": "https://images.pexels.com/photos/3184639/pexels-photo-3184639.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "9+ years in NLP and conversational AI development"
        },
        "curriculum": [
            {
                "week": "1",
                "title": "NLP Fundamentals",
                "duration": "10 hours",
                "topics": [
                    "NLP Tasks: Text classification, sentiment analysis, translation, summarization",
                    "Tokenization: Word, sentence, subword (Byte Pair Encoding, WordPiece)",
                    "Stemming/Lemmatization: Reducing words to base forms",
                    "Hands-on: Implement tokenizers, stemmers, lemmatizers on real text"
                ]
            },
            {
                "week": "2",
                "title": "Text Preprocessing & Feature Engineering",
                "duration": "10 hours",
                "topics": [
                    "Stopword Removal: Filtering common, non-informative words",
                    "n-grams: Capturing local context (bigrams, trigrams)",
                    "TF-IDF: Weighting terms by importance across documents",
                    "Word Embeddings: Word2Vec, GloVe, FastText",
                    "Hands-on: Clean and featurize corpus (product reviews, tweets)"
                ]
            },
            {
                "week": "3",
                "title": "Classical NLP Models",
                "duration": "10 hours",
                "topics": [
                    "Naive Bayes: Simple, fast baseline for text classification",
                    "SVM: Effective for high-dimensional, sparse text data",
                    "Logistic Regression: Interpretable, quick to train",
                    "Hands-on: Train, evaluate, and interpret models on labeled datasets"
                ]
            },
            {
                "week": "4",
                "title": "Deep Learning for NLP",
                "duration": "10 hours",
                "topics": [
                    "RNNs: Modeling sequences, vanishing gradient problem",
                    "LSTMs/GRUs: Long-term dependencies, gating mechanisms",
                    "Hands-on: Build sequence models for text generation, NER"
                ]
            },
            {
                "week": "5",
                "title": "Transformer Architectures",
                "duration": "10 hours",
                "topics": [
                    "BERT: Bidirectional, masked language modeling",
                    "GPT: Autoregressive, generative pre-training",
                    "T5: Text-to-text transfer transformer",
                    "Hugging Face Transformers: Load, fine-tune, deploy models",
                    "Hands-on: Fine-tune BERT/GPT on custom dataset"
                ]
            },
            {
                "week": "6",
                "title": "Named Entity Recognition & Sentiment Analysis",
                "duration": "10 hours",
                "topics": [
                    "NER: Identifying persons, organizations, locations in text",
                    "Sentiment Analysis: Detecting polarity (positive, negative, neutral)",
                    "Hands-on: Build NER and sentiment pipelines using SpaCy/Hugging Face"
                ]
            },
            {
                "week": "7",
                "title": "Introduction to Chatbot Development",
                "duration": "10 hours",
                "topics": [
                    "Rule-Based Bots: Simple pattern matching, decision trees",
                    "Rasa Framework: Open-source, customizable conversational AI",
                    "Hands-on: Build basic FAQ bot with Rasa"
                ]
            },
            {
                "week": "8",
                "title": "Conversational AI with LLMs",
                "duration": "10 hours",
                "topics": [
                    "LangChain: Orchestrate multi-step, tool-using chatbots",
                    "Prompt Engineering: Crafting inputs for GPT-4, Claude, LLaMA",
                    "Hands-on: Create chatbot using LangChain + OpenAI API"
                ]
            },
            {
                "week": "9",
                "title": "Multi-turn Conversations & Context Handling",
                "duration": "10 hours",
                "topics": [
                    "Memory: Retaining user context across turns",
                    "State Management: Tracking conversation flow, slots, entities",
                    "Hands-on: Enhance chatbot for follow-up questions and contextual replies"
                ]
            },
            {
                "week": "10",
                "title": "Deployment & API Integration",
                "duration": "10 hours",
                "topics": [
                    "FastAPI/Flask: Serve chatbot as REST API",
                    "Messaging Platforms: Integrate with Slack, WhatsApp, Messenger",
                    "Hands-on: Deploy bot to cloud, containerize, connect to chat platform"
                ]
            },
            {
                "week": "11",
                "title": "Analytics, Monitoring & Improvement",
                "duration": "10 hours",
                "topics": [
                    "Conversation Analytics: Track user queries, bot responses, drop-off",
                    "Feedback Loops: Collect user ratings, retrain models",
                    "Monitoring: Latency, error rates, data/model drift",
                    "Hands-on: Instrument bot with logging and analytics"
                ]
            },
            {
                "week": "12",
                "title": "Capstone & Final Assessment",
                "duration": "10 hours",
                "topics": [
                    "End-to-end chatbot project: e-commerce FAQ, healthcare checker",
                    "Code, documentation, deployed API, analytics dashboard",
                    "Technical quality, scalability, monitoring, user experience assessment"
                ]
            }
        ],
        "projects": [
            {
                "title": "AI-Powered E-commerce FAQ Chatbot",
                "description": "Build intelligent chatbot for e-commerce platform handling product queries, returns, and personalized recommendations with multi-turn conversations",
                "technologies": [
                    "Python",
                    "Rasa",
                    "FastAPI",
                    "LangChain"
                ],
                "image": "https://images.pexels.com/photos/230544/pexels-photo-230544.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Healthcare Symptom Checker Bot",
                "description": "Develop conversational AI that asks diagnostic questions, suggests possible conditions, and recommends next steps for healthcare",
                "technologies": [
                    "Python",
                    "Hugging Face",
                    "spaCy",
                    "OpenAI API"
                ],
                "image": "https://images.pexels.com/photos/4386370/pexels-photo-4386370.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Sentiment-Driven Customer Service Bot",
                "description": "Create intelligent routing system that analyzes customer sentiment and escalates negative cases to human agents automatically",
                "technologies": [
                    "Python",
                    "Transformers",
                    "Flask",
                    "NLTK"
                ],
                "image": "https://images.pexels.com/photos/3184431/pexels-photo-3184431.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Understand and implement core NLP preprocessing techniques",
            "Build and fine-tune transformer-based models for NLP tasks",
            "Design, train, and deploy chatbots for real-world scenarios",
            "Integrate NLP models with APIs and messaging platforms",
            "Monitor and improve chatbot performance using analytics",
            "Master conversational AI with context handling and memory",
            "Implement sentiment analysis and named entity recognition",
            "Deploy production-ready chatbots with monitoring and feedback loops"
        ],
        "prerequisites": [
            "Python programming proficiency",
            "Basic understanding of machine learning concepts",
            "Familiarity with text data and basic statistics",
            "Experience with APIs and web development (helpful but not required)"
        ],
        "courseOutcomes": [
            "Expertise in building intelligent chatbots and NLP applications",
            "Portfolio of 3+ deployed conversational AI projects",
            "Proficiency with modern NLP frameworks and transformer models",
            "Understanding of conversation design and user experience principles",
            "Knowledge of chatbot analytics, monitoring, and continuous improvement",
            "Preparation for NLP Engineer and Conversational AI Developer roles",
            "Skills in integrating chatbots with business systems and platforms",
            "Experience with multi-modal and context-aware dialogue systems"
        ],
        "toolsAndResources": {
            "platform": "Jupyter Notebook, VS Code, Google Colab",
            "libraries": [
                "Hugging Face Transformers",
                "spaCy",
                "NLTK",
                "Rasa",
                "LangChain",
                "FastAPI",
                "OpenAI API"
            ],
            "dataSources": [
                "Customer support logs",
                "Social media data",
                "FAQ databases",
                "Conversation datasets"
            ],
            "versionControl": "Git, GitHub for code management and collaboration",
            "assessment": [
                "Weekly NLP assignments",
                "Chatbot implementation projects",
                "Conversation design exercises",
                "Capstone deployment project"
            ]
        },
        "practicalExercises": [
            {
                "week": 1,
                "exercises": [
                    "Text preprocessing pipeline for social media data",
                    "Tokenization comparison across different languages",
                    "Stemming vs lemmatization performance analysis"
                ]
            },
            {
                "week": 2,
                "exercises": [
                    "TF-IDF feature extraction for document classification",
                    "Word2Vec training on domain-specific corpus",
                    "N-gram analysis for text similarity"
                ]
            },
            {
                "week": 3,
                "exercises": [
                    "Spam detection using Naive Bayes classifier",
                    "Multi-class text classification with SVM",
                    "Feature importance analysis in logistic regression"
                ]
            },
            {
                "week": 4,
                "exercises": [
                    "Sentiment analysis using LSTM networks",
                    "Text generation with RNN architectures",
                    "Sequence labeling for named entity recognition"
                ]
            },
            {
                "week": 5,
                "exercises": [
                    "Fine-tuning BERT for text classification tasks",
                    "GPT-based text completion and generation",
                    "Question-answering system using T5"
                ]
            },
            {
                "week": 6,
                "exercises": [
                    "Custom NER model training with spaCy",
                    "Multi-lingual sentiment analysis pipeline",
                    "Entity linking and knowledge graph integration"
                ]
            },
            {
                "week": 7,
                "exercises": [
                    "Rule-based chatbot with pattern matching",
                    "Intent classification and entity extraction",
                    "Dialogue flow design and testing"
                ]
            },
            {
                "week": 8,
                "exercises": [
                    "LangChain agent with tool integration",
                    "Prompt optimization for different use cases",
                    "Multi-step reasoning chatbot implementation"
                ]
            },
            {
                "week": 9,
                "exercises": [
                    "Conversation memory implementation",
                    "Context-aware response generation",
                    "State machine design for complex dialogues"
                ]
            },
            {
                "week": 10,
                "exercises": [
                    "REST API deployment with FastAPI",
                    "Webhook integration for messaging platforms",
                    "Chatbot performance optimization"
                ]
            },
            {
                "week": 11,
                "exercises": [
                    "Conversation analytics dashboard creation",
                    "A/B testing framework for chatbot responses",
                    "User feedback collection and analysis"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalImplementation": "Clean, efficient code with proper NLP techniques",
            "conversationDesign": "Natural, engaging dialogue flows and user experience",
            "systemIntegration": "Successful deployment and platform integration",
            "analytics": "Comprehensive monitoring and improvement strategies",
            "communication": "Clear documentation and presentation of chatbot capabilities"
        },
        "industryTrends": {
            "2025Trends": [
                "Multimodal chatbots (text + voice + image)",
                "Context-aware, long-term memory systems",
                "Domain-specific fine-tuned language models",
                "Real-time personalization and adaptation",
                "Ethical AI and bias mitigation in conversations"
            ],
            "jobMarketDemand": [
                "Conversational AI Engineers",
                "NLP Specialists",
                "Chatbot UX designers",
                "AI Product Managers",
                "Voice AI developers"
            ]
        }
    },
    "data-scientist-career-track": {
        "title": "Data Science Career Track — 2025 Edition",
        "description": "Master the complete data science pipeline from Python programming to advanced AI. Build production-ready skills in machine learning, deep learning, and business intelligence with hands-on projects and real-world applications.",
        "duration": "16 weeks (140 hours)",
        "level": "Intermediate to Advanced",
        "mode": "Online/Offline",
        "price": "₹25,000",
        "originalPrice": "₹35,000",
        "rating": 4.9,
        "students": 187,
        "nextBatch": "September 15, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-indigo-500 to-indigo-600",
        "icon": "TrendingUp",
        "image": "https://images.pexels.com/photos/3861958/pexels-photo-3861958.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python 3",
            "Pandas",
            "NumPy",
            "Scikit-learn",
            "TensorFlow",
            "PyTorch",
            "Apache Spark",
            "SQL",
            "MongoDB",
            "Docker",
            "Apache Superset",
            "Plotly",
            "SHAP",
            "XGBoost",
            "Kafka",
            "Git",
            "Jupyter",
            "FastAPI"
        ],
        "mentor": {
            "name": "Dr. Priya Sharma",
            "role": "Lead Data Scientist",
            "company": "Microsoft India",
            "image": "https://images.pexels.com/photos/3184360/pexels-photo-3184360.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "12+ years in data science, AI research, and enterprise machine learning"
        },
        "curriculum": [
            {
                "module": "1",
                "title": "Python Programming for Data Science",
                "duration": "25 hours",
                "topics": [
                    "Environment setup with Anaconda/Miniconda and virtual environments",
                    "Python fundamentals: variables, data types, control structures, functions",
                    "Object-oriented programming: classes, inheritance, error handling",
                    "NumPy for numerical computing and array operations",
                    "Pandas for data manipulation, cleaning, and analysis",
                    "Matplotlib and Seaborn for data visualization",
                    "Advanced Python: list comprehensions, generators, regular expressions",
                    "Web scraping with BeautifulSoup and API integration",
                    "Performance optimization and memory management"
                ]
            },
            {
                "module": "2",
                "title": "Mathematics & Statistics",
                "duration": "15 hours",
                "topics": [
                    "Descriptive statistics: central tendency, variability, distributions",
                    "Probability theory and probability distributions",
                    "Hypothesis testing, p-values, and confidence intervals",
                    "Correlation analysis and causation vs correlation",
                    "Linear algebra: vectors, matrices, eigenvalues, eigenvectors",
                    "Calculus for optimization: derivatives, gradients, gradient descent",
                    "Statistical tests: t-tests, chi-square, ANOVA",
                    "Principal Component Analysis (PCA) mathematics",
                    "Bayesian statistics and Bayes theorem applications"
                ]
            },
            {
                "module": "3",
                "title": "Data Engineering & Processing",
                "duration": "15 hours",
                "topics": [
                    "SQL fundamentals: queries, joins, subqueries, window functions",
                    "NoSQL databases: MongoDB integration with Python",
                    "API integration and authentication methods",
                    "Web scraping: static and dynamic content extraction",
                    "Data cleaning: missing values, outliers, data validation",
                    "Feature engineering and automated feature creation",
                    "Apache Spark and PySpark for big data processing",
                    "Apache Airflow for workflow orchestration",
                    "Data storage formats: CSV, Parquet, Avro optimization"
                ]
            },
            {
                "module": "4",
                "title": "Machine Learning & AI",
                "duration": "35 hours",
                "topics": [
                    "Supervised learning: linear/logistic regression, decision trees",
                    "Advanced algorithms: Random Forest, XGBoost, LightGBM",
                    "Support Vector Machines and kernel methods",
                    "Model evaluation: cross-validation, precision, recall, ROC curves",
                    "Unsupervised learning: K-means, hierarchical clustering, DBSCAN",
                    "Dimensionality reduction: PCA, t-SNE, UMAP",
                    "Deep learning fundamentals: neural networks, backpropagation",
                    "TensorFlow/Keras: building and training deep networks",
                    "Convolutional Neural Networks (CNNs) for image processing",
                    "Recurrent Neural Networks (RNNs) and LSTMs for sequences",
                    "Natural Language Processing: text preprocessing, TF-IDF, word embeddings",
                    "Advanced NLP: BERT, transformers, sentiment analysis, topic modeling"
                ]
            },
            {
                "module": "5",
                "title": "Advanced Analytics & AI Trends",
                "duration": "20 hours",
                "topics": [
                    "Automated Machine Learning (AutoML): Auto-sklearn, TPOT, H2O",
                    "Explainable AI: SHAP values, LIME, model interpretability",
                    "Bias detection and fairness in machine learning models",
                    "Generative AI: Large Language Models integration for data science",
                    "Prompt engineering for data analysis automation",
                    "Synthetic data generation using GANs and statistical methods",
                    "Stream processing with Apache Kafka for real-time analytics",
                    "Edge AI deployment and model optimization techniques",
                    "MLOps: model versioning, monitoring, and automated retraining"
                ]
            },
            {
                "module": "6",
                "title": "Business Intelligence & Visualization",
                "duration": "10 hours",
                "topics": [
                    "Advanced visualization with Plotly and Bokeh",
                    "Interactive dashboards and statistical chart types",
                    "Geographic visualization and mapping techniques",
                    "Data storytelling and presentation design principles",
                    "Apache Superset: installation, dashboard creation, SQL Lab",
                    "Metabase implementation for self-service analytics",
                    "Automated reporting systems and scheduled alerts",
                    "Real-time monitoring dashboards and KPI tracking"
                ]
            },
            {
                "module": "7",
                "title": "Capstone Projects",
                "duration": "15 hours",
                "topics": [
                    "End-to-end ML pipeline: from data collection to deployment",
                    "Real-time analytics dashboard with streaming data",
                    "AI-powered business intelligence with natural language queries",
                    "Production deployment using FastAPI and Docker",
                    "Portfolio development and GitHub documentation",
                    "Business impact assessment and ROI calculation",
                    "Technical and business presentation skills",
                    "Interview preparation and project showcase"
                ]
            }
        ],
        "projects": [
            {
                "title": "Customer Churn Prediction System",
                "description": "Build an end-to-end machine learning system to predict customer churn, including data pipeline, model training, and deployment with monitoring",
                "technologies": [
                    "Python",
                    "Scikit-learn",
                    "XGBoost",
                    "FastAPI",
                    "Docker"
                ],
                "image": "https://images.pexels.com/photos/3184298/pexels-photo-3184298.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Real-time Fraud Detection Dashboard",
                "description": "Create a streaming analytics system that processes transactions in real-time and flags potentially fraudulent activities with interactive visualizations",
                "technologies": [
                    "Python",
                    "Kafka",
                    "TensorFlow",
                    "Plotly",
                    "Apache Superset"
                ],
                "image": "https://images.pexels.com/photos/4386431/pexels-photo-4386431.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "AI-Powered Sentiment Analysis Platform",
                "description": "Develop a comprehensive NLP system for analyzing customer feedback across multiple channels with automated insights and reporting",
                "technologies": [
                    "Python",
                    "BERT",
                    "Hugging Face",
                    "MongoDB",
                    "Streamlit"
                ],
                "image": "https://images.pexels.com/photos/590022/pexels-photo-590022.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Recommendation Engine with Deep Learning",
                "description": "Build a sophisticated recommendation system using collaborative filtering and neural networks for e-commerce personalization",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "PySpark",
                    "Redis",
                    "PostgreSQL"
                ],
                "image": "https://images.pexels.com/photos/230544/pexels-photo-230544.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Automated Business Intelligence Suite",
                "description": "Create an AI-powered BI platform that automatically generates insights, reports, and visualizations from business data",
                "technologies": [
                    "Python",
                    "LLMs",
                    "Apache Superset",
                    "AutoML",
                    "Metabase"
                ],
                "image": "https://images.pexels.com/photos/669610/pexels-photo-669610.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Computer Vision Quality Control System",
                "description": "Develop a manufacturing quality control system using CNNs to automatically detect defects and anomalies in products",
                "technologies": [
                    "Python",
                    "OpenCV",
                    "TensorFlow",
                    "Docker",
                    "FastAPI"
                ],
                "image": "https://images.pexels.com/photos/3861969/pexels-photo-3861969.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master the complete data science workflow from data collection to model deployment",
            "Build production-ready machine learning systems with monitoring and maintenance",
            "Develop expertise in both traditional ML and cutting-edge deep learning techniques",
            "Create compelling data visualizations and business intelligence dashboards",
            "Implement real-time analytics and streaming data processing systems",
            "Apply explainable AI techniques for model interpretability and bias detection",
            "Integrate generative AI and LLMs into data science workflows",
            "Build a professional portfolio with diverse, industry-relevant projects",
            "Develop presentation skills for technical and business stakeholders",
            "Prepare for senior data scientist and ML engineer roles"
        ],
        "prerequisites": [
            "Basic Python programming knowledge (variables, loops, functions)",
            "Fundamental mathematics (algebra, basic statistics)",
            "Familiarity with data manipulation concepts",
            "Understanding of basic machine learning concepts is helpful but not required",
            "Strong analytical thinking and problem-solving skills",
            "Willingness to work with large datasets and complex algorithms"
        ],
        "courseOutcomes": [
            "Industry-ready skills for data scientist, ML engineer, and AI specialist roles",
            "Comprehensive portfolio with 6+ production-quality projects",
            "Expertise in both traditional analytics and modern AI techniques",
            "Ability to design and implement end-to-end data science solutions",
            "Proficiency in MLOps practices for model deployment and monitoring",
            "Advanced visualization and storytelling skills for business communication",
            "Understanding of ethical AI, bias detection, and responsible data science",
            "Preparation for senior roles with 3-5 years equivalent experience",
            "Network of industry connections and mentorship opportunities",
            "Certification and job placement assistance"
        ],
        "toolsAndResources": {
            "platform": "Jupyter Notebook, VS Code, Google Colab",
            "languages": [
                "Python 3",
                "SQL",
                "Bash/Shell scripting"
            ],
            "libraries": [
                "Pandas",
                "NumPy",
                "Scikit-learn",
                "TensorFlow",
                "PyTorch",
                "XGBoost",
                "SHAP",
                "Plotly",
                "Seaborn",
                "NLTK",
                "Hugging Face"
            ],
            "bigDataTools": [
                "Apache Spark",
                "Apache Kafka",
                "Apache Airflow",
                "Docker",
                "Redis"
            ],
            "databases": [
                "PostgreSQL",
                "MongoDB",
                "SQLite"
            ],
            "cloudPlatforms": [
                "AWS basics",
                "Google Cloud Platform",
                "Local deployment strategies"
            ],
            "biTools": [
                "Apache Superset",
                "Metabase",
                "Streamlit",
                "Dash"
            ],
            "versionControl": "Git and GitHub for code management and collaboration",
            "assessment": [
                "Weekly coding assignments",
                "Module-end projects",
                "Peer code reviews",
                "Capstone project presentation",
                "Industry mentor evaluation"
            ]
        },
        "practicalExercises": [
            {
                "module": 1,
                "exercises": [
                    "Multi-source data integration and cleaning pipeline",
                    "Web scraping project for real-time price monitoring",
                    "Performance optimization challenge for large datasets",
                    "API integration for external data enrichment"
                ]
            },
            {
                "module": 2,
                "exercises": [
                    "A/B test statistical analysis with business recommendations",
                    "Monte Carlo simulation for business risk assessment",
                    "PCA implementation from scratch using NumPy",
                    "Hypothesis testing framework for marketing campaigns"
                ]
            },
            {
                "module": 3,
                "exercises": [
                    "End-to-end ETL pipeline with error handling and monitoring",
                    "Big data processing using PySpark on distributed systems",
                    "Real-time data quality assessment and alerting system",
                    "Database optimization for analytical workloads"
                ]
            },
            {
                "module": 4,
                "exercises": [
                    "Multi-algorithm comparison for customer segmentation",
                    "Deep learning model for image classification with transfer learning",
                    "Time series forecasting using LSTM networks",
                    "NLP sentiment analysis system with BERT fine-tuning",
                    "Recommender system using collaborative filtering",
                    "Anomaly detection for fraud prevention"
                ]
            },
            {
                "module": 5,
                "exercises": [
                    "AutoML vs manual modeling performance comparison",
                    "Model explainability dashboard using SHAP and LIME",
                    "Bias detection and mitigation in hiring algorithms",
                    "LLM integration for automated data analysis",
                    "Real-time streaming analytics with Kafka",
                    "Edge deployment optimization for mobile devices"
                ]
            },
            {
                "module": 6,
                "exercises": [
                    "Executive dashboard with drill-down capabilities",
                    "Interactive geographic visualization for sales data",
                    "Automated reporting system with email notifications",
                    "Self-service analytics platform for business users",
                    "Real-time KPI monitoring dashboard"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalSkills": "Proficiency in programming, algorithms, and tools (40%)",
            "projectQuality": "Code quality, documentation, and best practices (25%)",
            "businessImpact": "Practical applicability and measurable outcomes (20%)",
            "communication": "Ability to explain technical concepts to various audiences (15%)",
            "innovation": "Creative problem-solving and use of advanced techniques (Bonus)"
        },
        "careerSupport": {
            "resumeReview": "Professional portfolio and resume optimization",
            "interviewPrep": "Technical and behavioral interview coaching",
            "jobPlacement": "Connections with hiring partners and job referrals",
            "networking": "Access to alumni network and industry events",
            "mentorship": "Ongoing guidance from industry professionals",
            "certifications": "Industry-recognized completion certificates"
        },
        "marketDemand": "Data Science remains one of the most in-demand career paths in 2025, with applications in AI, healthcare, finance, e-commerce, and technology. Reports predict 11+ million job openings globally by 2026. This course equips learners with hands-on, industry-ready skills."
    },
    "ml-engineer-career-track": {
        "title": "Machine Learning Career Track — 2025 Edition",
        "description": "Master end-to-end ML engineering with production-ready skills. Build scalable ML systems, deploy models at scale, and become a sought-after ML Engineer in product-based companies with hands-on MLOps expertise.",
        "duration": "20 weeks (140 hours)",
        "level": "Intermediate to Advanced",
        "mode": "Online/Offline",
        "price": "₹35,000",
        "originalPrice": "₹50,000",
        "rating": 4.8,
        "students": 156,
        "nextBatch": "October 1, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-indigo-600 to-purple-600",
        "icon": "Cpu",
        "image": "https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python 3",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "XGBoost",
            "Docker",
            "Kubernetes",
            "MLflow",
            "Apache Airflow",
            "FastAPI",
            "Apache Kafka",
            "PostgreSQL",
            "Redis",
            "Prometheus",
            "Grafana",
            "Git",
            "DVC",
            "Hugging Face",
            "OpenCV"
        ],
        "mentor": {
            "name": "Arjun Patel",
            "role": "Principal ML Engineer",
            "company": "Flipkart",
            "image": "https://images.pexels.com/photos/3184465/pexels-photo-3184465.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "10+ years in ML engineering, MLOps, and scalable AI systems at product companies"
        },
        "curriculum": [
            {
                "module": "1",
                "title": "Introduction to Machine Learning Engineering",
                "duration": "8 hours",
                "topics": [
                    "Modern ML Engineer role and responsibilities in product companies",
                    "Industry salary trends and career progression paths",
                    "End-to-end ML project lifecycle and production considerations",
                    "ML categories and modern applications in business",
                    "Supervised, unsupervised, and reinforcement learning use cases",
                    "Generative AI integration in ML workflows",
                    "Responsible AI and ethics: bias detection, explainable AI",
                    "Privacy-preserving ML and regulatory compliance",
                    "ML system design and architecture patterns"
                ]
            },
            {
                "module": "2",
                "title": "Python & Data Fundamentals",
                "duration": "15 hours",
                "topics": [
                    "Production Python practices: code organization, OOP, error handling",
                    "Type hints, testing frameworks, and performance optimization",
                    "Memory management, vectorization, and parallel processing",
                    "Development environments: virtual environments and Docker basics",
                    "Advanced NumPy: array operations, linear algebra, statistical functions",
                    "Pandas mastery: data structures, cleaning, groupby operations, time series",
                    "Large dataset handling: chunking, memory optimization, Dask integration",
                    "Feature engineering: numerical, categorical, text, and time-based features",
                    "Data visualization for ML: EDA, model performance, feature importance",
                    "Advanced visualization with Matplotlib, Seaborn, and Plotly"
                ]
            },
            {
                "module": "3",
                "title": "Statistics & Mathematics for ML",
                "duration": "12 hours",
                "topics": [
                    "Probability fundamentals and Bayesian thinking in ML",
                    "Statistical inference: hypothesis testing, A/B testing, bootstrap methods",
                    "Descriptive statistics and distribution analysis for ML",
                    "Parametric and non-parametric statistical tests",
                    "Linear algebra for ML: vectors, matrices, eigendecomposition, SVD",
                    "Calculus and optimization: gradients, gradient descent variants",
                    "Convex optimization and constrained optimization",
                    "Stochastic optimization: SGD, momentum, Adam optimizers",
                    "Mathematical foundations of PCA and dimensionality reduction"
                ]
            },
            {
                "module": "4",
                "title": "Machine Learning Foundations",
                "duration": "20 hours",
                "topics": [
                    "Advanced data preprocessing and pipeline design",
                    "Feature selection: filter, wrapper, and embedded methods",
                    "Scikit-learn pipelines and custom transformers",
                    "Linear models: regression, logistic regression, regularization",
                    "Tree-based models: decision trees, random forest, gradient boosting",
                    "XGBoost, LightGBM, CatBoost: advanced features and tuning",
                    "Support Vector Machines and kernel methods",
                    "Ensemble methods: voting, stacking, meta-learning",
                    "Model evaluation metrics and cross-validation strategies",
                    "Hyperparameter optimization: grid search, Bayesian optimization",
                    "Handling imbalanced data and time series fundamentals",
                    "Anomaly detection techniques and evaluation methods"
                ]
            },
            {
                "module": "5",
                "title": "Advanced Machine Learning & Deep Learning",
                "duration": "25 hours",
                "topics": [
                    "Neural network fundamentals: perceptron, backpropagation, optimization",
                    "Network architecture design: activation functions, regularization, loss functions",
                    "TensorFlow & Keras: model APIs, custom components, data pipeline",
                    "PyTorch fundamentals: tensor operations, modules, training loops",
                    "Model deployment: SavedModel, TorchScript, ONNX export",
                    "Convolutional Neural Networks: architecture, transfer learning, data augmentation",
                    "Advanced CV techniques: object detection, segmentation, GANs",
                    "Recurrent Neural Networks: LSTM, GRU, sequence modeling",
                    "Attention mechanisms and Transformer architecture",
                    "Pre-trained models: BERT, GPT, T5 for downstream tasks",
                    "Fine-tuning strategies and parameter-efficient methods"
                ]
            },
            {
                "module": "6",
                "title": "NLP & Computer Vision Applications",
                "duration": "15 hours",
                "topics": [
                    "Advanced text preprocessing and modern tokenization methods",
                    "Transformer-based models: Hugging Face ecosystem and model hub",
                    "BERT family, GPT family, T5 for various NLP tasks",
                    "Fine-tuning strategies and model evaluation for NLP",
                    "Production NLP applications: classification, NER, QA, summarization",
                    "Image processing with OpenCV: filtering, feature detection, tracking",
                    "Deep learning for computer vision: pre-trained models, transfer learning",
                    "Object detection with YOLO, image segmentation techniques",
                    "Face recognition and generative models for computer vision",
                    "Real-time inference optimization and model deployment"
                ]
            },
            {
                "module": "7",
                "title": "MLOps & Model Deployment",
                "duration": "25 hours",
                "topics": [
                    "MLOps fundamentals and maturity levels",
                    "Experiment tracking with MLflow and Weights & Biases",
                    "Data and model versioning with DVC",
                    "Feature stores and training-serving consistency",
                    "Workflow orchestration with Apache Airflow and Kubeflow",
                    "Docker for ML: containerization, optimization, GPU support",
                    "Model serving with FastAPI, TensorFlow Serving, Triton",
                    "API design, performance optimization, and security",
                    "Kubernetes for ML: container orchestration, scaling, resource management",
                    "Cloud deployment strategies and cost optimization",
                    "CI/CD for ML: version control, automated testing, deployment pipelines",
                    "Production monitoring and maintenance strategies"
                ]
            },
            {
                "module": "8",
                "title": "Capstone Projects",
                "duration": "12 hours",
                "topics": [
                    "Healthcare AI: disease risk prediction with HIPAA compliance",
                    "E-commerce demand forecasting with hierarchical models",
                    "Manufacturing defect detection with computer vision",
                    "Intelligent customer support system with NLP",
                    "Personalized recommendation engine with real-time serving",
                    "End-to-end project execution: planning, development, deployment",
                    "Business impact assessment and ROI calculation",
                    "Technical documentation and presentation skills"
                ]
            },
            {
                "module": "9",
                "title": "Career Preparation",
                "duration": "3 hours",
                "topics": [
                    "Professional profile development for ML Engineer roles",
                    "Resume optimization and LinkedIn portfolio building",
                    "Technical interview preparation: coding, system design, ML fundamentals",
                    "Behavioral interview skills and salary negotiation",
                    "Job search strategy and target company research",
                    "Continuous learning and staying updated with ML trends"
                ]
            }
        ],
        "projects": [
            {
                "title": "Healthcare Disease Risk Prediction System",
                "description": "Build HIPAA-compliant ML system for predicting disease risk using electronic health records with real-time risk scoring and audit logging",
                "technologies": [
                    "Python",
                    "Scikit-learn",
                    "FastAPI",
                    "Docker",
                    "PostgreSQL"
                ],
                "image": "https://images.pexels.com/photos/3938023/pexels-photo-3938023.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "E-commerce Demand Forecasting Platform",
                "description": "Develop hierarchical forecasting system for thousands of products with seasonal decomposition, external factors, and inventory optimization",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "Apache Airflow",
                    "Docker",
                    "Kubernetes"
                ],
                "image": "https://images.pexels.com/photos/3184339/pexels-photo-3184339.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Manufacturing Quality Control System",
                "description": "Create real-time defect detection system using computer vision with edge deployment, IoT integration, and automated alerts",
                "technologies": [
                    "Python",
                    "OpenCV",
                    "PyTorch",
                    "FastAPI",
                    "Redis"
                ],
                "image": "https://images.pexels.com/photos/3861969/pexels-photo-3861969.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Intelligent Customer Support Chatbot",
                "description": "Build AI-powered chatbot with intent recognition, entity extraction, and RAG-based response generation with multi-language support",
                "technologies": [
                    "Python",
                    "Hugging Face",
                    "BERT",
                    "MongoDB",
                    "Apache Kafka"
                ],
                "image": "https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Real-time Recommendation Engine",
                "description": "Develop scalable recommendation system with collaborative filtering, deep learning embeddings, and A/B testing framework",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "Apache Kafka",
                    "Redis",
                    "Docker"
                ],
                "image": "https://images.pexels.com/photos/590022/pexels-photo-590022.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Fraud Detection System with MLOps",
                "description": "Build complete fraud detection pipeline with real-time streaming, model monitoring, automated retraining, and explainable AI",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "MLflow",
                    "Kubernetes",
                    "Prometheus"
                ],
                "image": "https://images.pexels.com/photos/4386431/pexels-photo-4386431.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master end-to-end ML engineering lifecycle from problem definition to production deployment",
            "Build production-ready ML systems with scalability, monitoring, and maintenance capabilities",
            "Develop expertise in MLOps practices including CI/CD, model versioning, and automated testing",
            "Create robust data pipelines and feature engineering systems for large-scale applications",
            "Implement advanced ML algorithms including deep learning and transformer models",
            "Deploy models using containerization, orchestration, and cloud-native technologies",
            "Apply responsible AI practices with bias detection and explainable AI techniques",
            "Build professional portfolio demonstrating industry-ready ML engineering skills",
            "Develop system design skills for scalable ML infrastructure",
            "Prepare for senior ML Engineer roles in product-based companies"
        ],
        "prerequisites": [
            "Strong Python programming skills with data structures and algorithms knowledge",
            "Basic understanding of machine learning concepts and supervised learning",
            "Familiarity with data manipulation using pandas and NumPy",
            "Understanding of software engineering principles and version control (Git)",
            "Basic knowledge of databases and SQL queries",
            "Mathematical foundation in statistics, linear algebra, and calculus",
            "Experience with Jupyter notebooks and development environments",
            "Willingness to work with complex, large-scale systems and data"
        ],
        "courseOutcomes": [
            "Industry-ready ML Engineer skills for product-based companies (₹12-40 LPA salary range)",
            "Comprehensive portfolio with 6+ production-quality ML systems",
            "Expertise in modern MLOps tools and practices for scalable deployment",
            "Advanced knowledge of deep learning, NLP, and computer vision applications",
            "Proficiency in containerization, orchestration, and cloud deployment strategies",
            "Strong foundation in system design for ML infrastructure and scalability",
            "Understanding of responsible AI, ethics, and regulatory compliance",
            "Preparation for senior roles with 3-7 years equivalent industry experience",
            "Professional network and mentorship from industry experts",
            "Job placement assistance and interview preparation for target companies"
        ],
        "toolsAndResources": {
            "platform": "Jupyter Notebook, VS Code, Docker, Kubernetes",
            "languages": [
                "Python 3.9+",
                "SQL",
                "Bash/Shell scripting"
            ],
            "mlFrameworks": [
                "TensorFlow",
                "PyTorch",
                "Scikit-learn",
                "XGBoost",
                "LightGBM",
                "CatBoost",
                "Hugging Face Transformers"
            ],
            "dataProcessing": [
                "Pandas",
                "NumPy",
                "Polars",
                "Dask",
                "Apache Spark"
            ],
            "mlopsTools": [
                "MLflow",
                "Weights & Biases",
                "DVC",
                "Apache Airflow",
                "Kubeflow Pipelines"
            ],
            "deployment": [
                "Docker",
                "Kubernetes",
                "FastAPI",
                "Flask",
                "TensorFlow Serving",
                "Triton Inference Server"
            ],
            "infrastructure": [
                "PostgreSQL",
                "MongoDB",
                "Redis",
                "Apache Kafka",
                "RabbitMQ",
                "MinIO"
            ],
            "monitoring": [
                "Prometheus",
                "Grafana",
                "Elasticsearch",
                "Kibana"
            ],
            "cicd": [
                "Git",
                "GitHub Actions",
                "GitLab CI",
                "Docker Registry"
            ],
            "specialized": [
                "OpenCV",
                "spaCy",
                "NLTK",
                "Prophet",
                "Matplotlib",
                "Seaborn",
                "Plotly"
            ],
            "assessment": [
                "Hands-on coding assignments",
                "System design challenges",
                "Production deployment projects",
                "Peer code reviews",
                "Capstone project presentations",
                "Industry mentor evaluations"
            ]
        },
        "practicalExercises": [
            {
                "module": 1,
                "exercises": [
                    "ML system design for fraud detection with scalability considerations",
                    "Ethics case study analysis with bias mitigation strategies",
                    "ROI calculation for ML solution including infrastructure costs",
                    "Career progression planning for ML Engineer roles"
                ]
            },
            {
                "module": 2,
                "exercises": [
                    "Production data pipeline with error handling and validation",
                    "Advanced EDA with multiple data types and missing values",
                    "Feature engineering competition with performance comparison",
                    "Interactive dashboard for ML model insights"
                ]
            },
            {
                "module": 3,
                "exercises": [
                    "Statistical analysis with hypothesis testing and business recommendations",
                    "Optimization algorithm implementation from scratch",
                    "PCA implementation using NumPy with performance comparison",
                    "A/B test design with power analysis and significance testing"
                ]
            },
            {
                "module": 4,
                "exercises": [
                    "End-to-end fraud detection system with production considerations",
                    "Multi-algorithm comparison with proper cross-validation",
                    "Advanced hyperparameter tuning using Bayesian optimization",
                    "Imbalanced dataset handling with multiple techniques",
                    "Time series forecasting with seasonal patterns"
                ]
            },
            {
                "module": 5,
                "exercises": [
                    "Image classification with transfer learning and optimization",
                    "Multi-variate time series forecasting with attention mechanisms",
                    "Text classification with BERT fine-tuning",
                    "Custom neural architecture design and performance comparison",
                    "Model optimization for inference speed and memory usage"
                ]
            },
            {
                "module": 6,
                "exercises": [
                    "End-to-end sentiment analysis API with domain adaptation",
                    "Multi-class document classifier with hierarchical attention",
                    "Real-time object detection system with performance optimization",
                    "Multimodal visual question answering system",
                    "Content moderation for text and images"
                ]
            },
            {
                "module": 7,
                "exercises": [
                    "Complete MLOps pipeline with experiment tracking and deployment",
                    "Model serving system with containerization and monitoring",
                    "CI/CD implementation with automated testing and deployment",
                    "Production monitoring dashboard with drift detection",
                    "A/B testing framework for model version comparison"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalProficiency": "ML algorithms, programming skills, system design (35%)",
            "mlopsExpertise": "Deployment, monitoring, CI/CD, production readiness (30%)",
            "projectQuality": "Code quality, documentation, scalability, best practices (20%)",
            "businessImpact": "Problem-solving, practical applicability, measurable outcomes (10%)",
            "communication": "Technical presentation, documentation, stakeholder interaction (5%)"
        },
        "careerSupport": {
            "portfolioBuilding": "GitHub portfolio optimization with production-quality projects",
            "resumeOptimization": "ML Engineer-specific resume review and LinkedIn enhancement",
            "interviewPreparation": "Technical interviews, system design, coding challenges, behavioral questions",
            "jobPlacement": "Direct connections with product companies and hiring partners",
            "salaryNegotiation": "Market research, compensation benchmarking, offer negotiation",
            "networking": "Alumni network access, industry meetups, professional connections",
            "mentorship": "Ongoing guidance from senior ML Engineers and industry leaders",
            "continuousLearning": "Access to advanced courses and latest ML technology updates"
        },
        "industryAlignment": {
            "marketDemand": "ML Engineers are among the highest-paid tech roles with ₹12-40 LPA in product companies. 85% job growth expected by 2027.",
            "skillsGap": "Focus on production ML skills that companies actually need vs traditional academic ML",
            "latestTrends": [
                "Generative AI integration in ML workflows (covered)",
                "MLOps and production deployment (core focus)",
                "Edge AI and model optimization (included)",
                "Responsible AI and bias detection (emphasized)",
                "Real-time ML systems (hands-on projects)"
            ],
            "targetCompanies": [
                "Product-based companies: Flipkart, Zomato, Paytm, Ola, Swiggy",
                "Tech giants: Microsoft, Google, Amazon (India offices)",
                "Startups: Unicorns and high-growth startups with ML teams",
                "Financial services: Banks, fintech companies with ML use cases",
                "E-commerce and consumer tech companies"
            ]
        },
        "openSourceStack": {
            "note": "Complete course uses open-source tools only, ensuring no vendor lock-in and maximum accessibility",
            "alternatives": {
                "cloudServices": "MinIO (S3 alternative), OpenStack (compute), local Kubernetes",
                "monitoring": "Prometheus + Grafana (instead of paid APM tools)",
                "mlPlatforms": "MLflow + Kubeflow (instead of AWS SageMaker)",
                "databases": "PostgreSQL, MongoDB, Redis (no proprietary databases)"
            }
        }
    },
    "ai-engineer-career-track": {
        "title": "AI Engineer Career Track — 2025 Edition",
        "description": "Master the latest AI engineering skills including Generative AI, LLMs, Deep Learning, and production AI systems. Build end-to-end AI applications with hands-on projects and industry-ready expertise.",
        "duration": "24 weeks (150 hours)",
        "level": "Intermediate to Advanced",
        "mode": "Online/Offline",
        "price": "₹45,000",
        "originalPrice": "₹65,000",
        "rating": 4.9,
        "students": 187,
        "nextBatch": "September 15, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-indigo-500 to-indigo-600",
        "icon": "Bot",
        "image": "https://images.pexels.com/photos/8386434/pexels-photo-8386434.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "Hugging Face",
            "LangChain",
            "OpenAI",
            "FastAPI",
            "Docker",
            "Kubernetes",
            "MLOps",
            "Transformers",
            "Computer Vision",
            "NLP",
            "RAG Systems"
        ],
        "mentor": {
            "name": "Dr. Priya Sharma",
            "role": "Principal AI Engineer",
            "company": "Microsoft India",
            "image": "https://images.pexels.com/photos/3184465/pexels-photo-3184465.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "12+ years in AI research and production systems, former Google AI researcher"
        },
        "curriculum": [
            {
                "module": "1",
                "title": "Introduction to AI Engineering",
                "duration": "10 hours",
                "topics": [
                    "AI Engineer role in 2025 vs ML Engineer vs Data Scientist",
                    "Modern AI system architecture and design patterns",
                    "Types of AI: Narrow AI, AGI concepts, and current applications",
                    "AI development lifecycle and production considerations",
                    "Ethics and responsible AI practices",
                    "Industry salary trends and career progression paths"
                ]
            },
            {
                "module": "2",
                "title": "Python & Data Fundamentals",
                "duration": "12 hours",
                "topics": [
                    "Advanced Python for AI: OOP, async programming, performance optimization",
                    "NumPy and Pandas for large-scale data processing",
                    "API integration and real-time data processing",
                    "Working with unstructured data: JSON, images, audio, video",
                    "Data visualization with Matplotlib, Seaborn, and Plotly",
                    "Building robust data pipelines for AI applications"
                ]
            },
            {
                "module": "3",
                "title": "Mathematics & AI Foundations",
                "duration": "13 hours",
                "topics": [
                    "Linear algebra: vectors, matrices, eigenvalues for AI",
                    "Probability and statistics: Bayesian inference, information theory",
                    "Calculus and optimization: gradient descent, Adam, advanced optimizers",
                    "Graph theory: search algorithms, neural networks, knowledge graphs",
                    "Mathematical foundations of neural networks and deep learning"
                ]
            },
            {
                "module": "4",
                "title": "Machine Learning for AI Engineers",
                "duration": "18 hours",
                "topics": [
                    "Advanced feature engineering and selection techniques",
                    "Supervised learning: linear models, tree-based, ensemble methods",
                    "Unsupervised learning: clustering, dimensionality reduction, anomaly detection",
                    "Model evaluation, cross-validation, and hyperparameter tuning",
                    "Handling imbalanced data and real-world ML challenges",
                    "AutoML and model interpretability with SHAP and LIME"
                ]
            },
            {
                "module": "5",
                "title": "Deep Learning & Neural Architectures",
                "duration": "22 hours",
                "topics": [
                    "Neural network fundamentals and backpropagation",
                    "TensorFlow and PyTorch mastery for production",
                    "CNNs: architecture design, transfer learning, object detection",
                    "RNNs and sequence modeling: LSTM, GRU, time series",
                    "Attention mechanisms and transformer architecture",
                    "Advanced training techniques and optimization strategies"
                ]
            },
            {
                "module": "6",
                "title": "Generative AI & Large Language Models",
                "duration": "20 hours",
                "topics": [
                    "Generative models: GANs, VAEs, and diffusion models",
                    "LLM architecture: GPT, BERT, T5, and modern variants",
                    "Fine-tuning strategies: LoRA, QLoRA, instruction tuning",
                    "Prompt engineering and advanced prompting techniques",
                    "RAG systems with vector databases and embeddings",
                    "Building production LLM applications with LangChain"
                ]
            },
            {
                "module": "7",
                "title": "NLP & Computer Vision Applications",
                "duration": "15 hours",
                "topics": [
                    "Modern NLP pipelines with transformers",
                    "Text classification, NER, sentiment analysis, and summarization",
                    "Computer vision: image classification, object detection, segmentation",
                    "Multi-modal AI systems combining text and vision",
                    "Real-time processing and performance optimization",
                    "Domain-specific applications and custom model development"
                ]
            },
            {
                "module": "8",
                "title": "AI System Design & MLOps",
                "duration": "15 hours",
                "topics": [
                    "Scalable AI architecture: microservices, event-driven design",
                    "Model deployment strategies and serving infrastructure",
                    "MLOps pipelines: experiment tracking, model registry, CI/CD",
                    "Monitoring and maintenance of production AI systems",
                    "Containerization with Docker and Kubernetes orchestration",
                    "Cost optimization and performance tuning"
                ]
            },
            {
                "module": "9",
                "title": "Capstone Projects",
                "duration": "15 hours",
                "topics": [
                    "Generative AI Marketing Assistant with personalized content",
                    "Autonomous Retail Checkout System with computer vision",
                    "AI Healthcare Diagnostic Assistant with multi-modal analysis",
                    "Real-time Translation System with speech processing",
                    "Video Content Analyzer with summarization capabilities"
                ]
            },
            {
                "module": "10",
                "title": "Career Preparation",
                "duration": "5 hours",
                "topics": [
                    "Portfolio development and GitHub optimization",
                    "Technical interview preparation for AI roles",
                    "System design interviews for AI systems",
                    "Job search strategy and salary negotiation",
                    "Professional networking and industry connections"
                ]
            }
        ],
        "projects": [
            {
                "title": "Intelligent Customer Service Chatbot",
                "description": "Build an advanced chatbot using fine-tuned LLMs with RAG capabilities, handling complex customer queries with context awareness and multi-turn conversations",
                "technologies": [
                    "Python",
                    "Hugging Face",
                    "LangChain",
                    "ChromaDB",
                    "FastAPI"
                ],
                "image": "https://images.pexels.com/photos/8386434/pexels-photo-8386434.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Real-time Object Detection System",
                "description": "Develop a production-ready computer vision system for real-time object detection and tracking with custom model training and edge deployment",
                "technologies": [
                    "PyTorch",
                    "YOLO v8",
                    "OpenCV",
                    "TensorRT",
                    "Docker"
                ],
                "image": "https://images.pexels.com/photos/2599244/pexels-photo-2599244.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Multimodal Content Generation Platform",
                "description": "Create a platform that generates personalized marketing content combining text and images using GANs and fine-tuned language models",
                "technologies": [
                    "Stable Diffusion",
                    "GPT",
                    "Streamlit",
                    "AWS S3",
                    "MongoDB"
                ],
                "image": "https://images.pexels.com/photos/3861969/pexels-photo-3861969.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Sentiment Analysis & Market Prediction",
                "description": "Build an AI system that analyzes social media sentiment and news to predict market trends using ensemble learning and time series forecasting",
                "technologies": [
                    "BERT",
                    "LSTM",
                    "Pandas",
                    "Plotly",
                    "Apache Kafka"
                ],
                "image": "https://images.pexels.com/photos/590022/pexels-photo-590022.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Document Intelligence System",
                "description": "Develop an AI system for automated document processing, information extraction, and classification using modern NLP and computer vision techniques",
                "technologies": [
                    "TrOCR",
                    "spaCy",
                    "Tesseract",
                    "PostgreSQL",
                    "Redis"
                ],
                "image": "https://images.pexels.com/photos/1181677/pexels-photo-1181677.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "AI-Powered Code Assistant",
                "description": "Create an intelligent coding assistant that can understand, generate, and debug code using fine-tuned code generation models with context awareness",
                "technologies": [
                    "CodeLlama",
                    "Tree-sitter",
                    "FastAPI",
                    "WebSockets",
                    "VSCode Extension"
                ],
                "image": "https://images.pexels.com/photos/4164418/pexels-photo-4164418.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master end-to-end AI system development from concept to production",
            "Build expertise in generative AI, LLMs, and modern transformer architectures",
            "Develop skills in computer vision, NLP, and multimodal AI applications",
            "Learn production AI deployment with MLOps and scalable architecture",
            "Create a comprehensive portfolio demonstrating diverse AI capabilities",
            "Understand AI ethics, bias mitigation, and responsible AI practices",
            "Gain experience with industry-standard tools and frameworks",
            "Prepare for senior AI engineering roles with ₹30-50 LPA salaries"
        ],
        "prerequisites": [
            "Strong Python programming skills (equivalent to our Python for Data & AI track)",
            "Basic understanding of mathematics (linear algebra, calculus, statistics)",
            "Familiarity with machine learning concepts (recommended but not mandatory)",
            "Experience with data manipulation libraries (Pandas, NumPy)",
            "Access to GPU-capable machine or willingness to use cloud services"
        ],
        "courseOutcomes": [
            "Ability to design and implement complex AI systems for production environments",
            "Expertise in fine-tuning and deploying large language models",
            "Skills to build multimodal AI applications combining text, image, and audio",
            "Understanding of MLOps practices for AI model lifecycle management",
            "Portfolio of 6+ industry-ready projects showcasing diverse AI capabilities",
            "Preparation for roles like AI Engineer, ML Engineer, AI Researcher",
            "Network of AI professionals and mentors in the industry",
            "Confidence to lead AI initiatives and architect AI solutions"
        ],
        "toolsAndResources": {
            "frameworks": [
                "TensorFlow",
                "PyTorch",
                "Hugging Face Transformers",
                "LangChain",
                "LlamaIndex"
            ],
            "platforms": [
                "Jupyter Lab",
                "Google Colab",
                "Weights & Biases",
                "MLflow",
                "Docker"
            ],
            "databases": [
                "ChromaDB",
                "FAISS",
                "PostgreSQL",
                "Redis",
                "MongoDB"
            ],
            "deployment": [
                "FastAPI",
                "Streamlit",
                "Docker",
                "Kubernetes",
                "AWS/GCP"
            ],
            "assessment": [
                "Weekly coding assignments",
                "Module-end projects",
                "Peer code reviews",
                "Capstone project presentation"
            ]
        },
        "practicalExercises": [
            {
                "module": 1,
                "exercises": [
                    "AI use case mapping for healthcare, finance, and retail",
                    "Complete AI system architecture design",
                    "Ethics assessment and bias mitigation strategies"
                ]
            },
            {
                "module": 2,
                "exercises": [
                    "Multi-source data pipeline with error handling",
                    "Real-time async data processor",
                    "Interactive data exploration dashboard"
                ]
            },
            {
                "module": 3,
                "exercises": [
                    "PCA implementation from scratch",
                    "Optimization algorithm visualization",
                    "Graph analysis with community detection"
                ]
            },
            {
                "module": 4,
                "exercises": [
                    "Advanced spam detection system",
                    "Customer segmentation with business insights",
                    "Model interpretability dashboard"
                ]
            },
            {
                "module": 5,
                "exercises": [
                    "Custom CNN architecture design",
                    "LSTM time series forecasting",
                    "Transformer fine-tuning for domain tasks"
                ]
            },
            {
                "module": 6,
                "exercises": [
                    "Custom LLM fine-tuning with LoRA",
                    "Complete RAG system implementation",
                    "Multi-agent LLM collaboration system"
                ]
            },
            {
                "module": 7,
                "exercises": [
                    "Multilingual text classifier",
                    "Real-time object detection system",
                    "Multimodal search engine"
                ]
            },
            {
                "module": 8,
                "exercises": [
                    "Complete MLOps pipeline setup",
                    "Production LLM deployment",
                    "AI monitoring and alerting system"
                ]
            }
        ],
        "assessmentCriteria": {
            "technicalExcellence": "Code quality, architecture design, performance optimization",
            "innovation": "Creative problem-solving, novel approaches, technical depth",
            "businessImpact": "Practical applicability, value proposition, scalability",
            "documentation": "Code documentation, technical writing, presentation skills",
            "demonstration": "Live demo capability, error handling, user experience"
        },
        "careerSupport": {
            "placementAssistance": "Resume building, interview preparation, company referrals",
            "industryConnections": "Networking events, mentorship programs, alumni network",
            "continuousLearning": "Access to latest research papers, industry updates, advanced workshops",
            "certificationPath": "Preparation for AWS ML, Google Cloud ML, Azure AI certifications"
        },
        "salaryOutcomes": {
            "juniorAIEngineer": "₹15-25 LPA",
            "aiEngineer": "₹25-40 LPA",
            "seniorAIEngineer": "₹35-55 LPA",
            "aiArchitect": "₹50-80 LPA"
        },
        "industryPartners": [
            "Microsoft",
            "Google",
            "Amazon",
            "Flipkart",
            "Zomato",
            "Paytm",
            "Freshworks",
            "Razorpay"
        ]
    },
    "gen-ai-engineer-career-track": {
        "title": "Gen AI Engineer Career Track — 2025 Edition",
        "description": "Master the cutting-edge world of Generative AI with hands-on experience in LLMs, image generation, audio synthesis, and multimodal systems. Build production-ready GenAI applications with the latest tools and techniques.",
        "duration": "20 weeks (130 hours)",
        "level": "Intermediate to Advanced",
        "mode": "Online/Offline",
        "price": "₹42,000",
        "originalPrice": "₹60,000",
        "rating": 4.8,
        "students": 143,
        "nextBatch": "September 8, 2025",
        "category": "AI/ML/Data Science/Gen AI",
        "color": "from-pink-500 to-purple-700",
        "icon": "Sparkles",
        "image": "https://images.pexels.com/photos/8386749/pexels-photo-8386749.jpeg?auto=compress&cs=tinysrgb&w=800&h=400&fit=crop",
        "technologies": [
            "Python",
            "PyTorch",
            "Hugging Face",
            "LangChain",
            "Stable Diffusion",
            "Whisper",
            "FastAPI",
            "Docker",
            "Kubernetes",
            "MLOps",
            "GANs",
            "VAEs",
            "Transformers",
            "RAG",
            "LoRA"
        ],
        "mentor": {
            "name": "Arjun Mehta",
            "role": "Lead Gen AI Engineer",
            "company": "Flipkart Labs",
            "image": "https://images.pexels.com/photos/3785077/pexels-photo-3785077.jpeg?auto=compress&cs=tinysrgb&w=150&h=150&fit=crop",
            "experience": "10+ years in AI research and Gen AI product development, former OpenAI contributor"
        },
        "curriculum": [
            {
                "module": "1",
                "title": "Introduction to Generative AI",
                "duration": "8 hours",
                "topics": [
                    "What is Generative AI vs traditional discriminative ML",
                    "Evolution of GenAI: GANs, VAEs, Diffusion Models, LLMs",
                    "Current applications in content creation, healthcare, e-commerce",
                    "Bengaluru GenAI ecosystem and local startup landscape",
                    "Ethics and responsibility: copyright, deepfakes, bias, Indian regulations",
                    "Career landscape: roles, salaries, and in-demand skills"
                ]
            },
            {
                "module": "2",
                "title": "Python & AI Foundations",
                "duration": "10 hours",
                "topics": [
                    "Python mastery: functions, classes, decorators, error handling, logging",
                    "Data engineering: NumPy tensors, Pandas, Polars for big data",
                    "Visualization: Matplotlib, Seaborn, Plotly for dashboards",
                    "APIs and JSON: async requests, pagination, caching, rate limits",
                    "Cloud-native development: virtualenv, Docker basics, GitHub, CLI tools",
                    "Production-grade coding practices for GenAI applications"
                ]
            },
            {
                "module": "3",
                "title": "Mathematics for Generative Models",
                "duration": "12 hours",
                "topics": [
                    "Linear algebra: vectors, matrices, tensor operations, SVD, eigendecomposition",
                    "Probability theory: distributions, Bayes' rule, Markov chains",
                    "Calculus: derivatives, gradients, backpropagation, optimization",
                    "Information theory: entropy, KL divergence, GAN/VAE loss functions",
                    "Implementation from scratch using Python and NumPy",
                    "Mathematical foundations of generative modeling"
                ]
            },
            {
                "module": "4",
                "title": "Machine Learning Essentials for GenAI",
                "duration": "10 hours",
                "topics": [
                    "ML fundamentals: supervised vs unsupervised, clustering, regression, classification",
                    "Feature engineering: text, image, audio feature extraction, embeddings",
                    "Evaluation metrics: BLEU, FID, Inception Score, CLIP score, human evaluation",
                    "Pre-training tasks: sentiment, topic, intent classification for LLM foundation",
                    "Traditional ML vs neural approaches for generative tasks",
                    "Building strong base models for fine-tuning"
                ]
            },
            {
                "module": "5",
                "title": "Deep Learning Foundations",
                "duration": "12 hours",
                "topics": [
                    "Neural networks: perceptrons, activation functions, loss, optimization",
                    "CNNs: convolution, pooling, ResNet, EfficientNet architectures",
                    "RNNs and LSTMs: sequence modeling, time series, text generation",
                    "Transformers: self-attention, multi-head attention, positional encoding",
                    "Training techniques: mixed precision, gradient clipping, LR scheduling",
                    "Debugging and optimization strategies for deep learning"
                ]
            },
            {
                "module": "6",
                "title": "Text Generation & LLMs",
                "duration": "14 hours",
                "topics": [
                    "Open-source LLMs: Llama 2, Mistral, BERT, T5, multilingual models",
                    "Prompt engineering: zero-shot, few-shot, chain-of-thought, constitutional AI",
                    "LangChain and LlamaIndex: agents, tools, memory, document retrieval",
                    "Fine-tuning techniques: LoRA, QLoRA, adapter methods, dataset preparation",
                    "RAG systems: ChromaDB, FAISS, semantic search, hybrid retrieval",
                    "Production deployment of LLM applications"
                ]
            },
            {
                "module": "7",
                "title": "Image Generation & Diffusion Models",
                "duration": "12 hours",
                "topics": [
                    "GANs: DCGAN, StyleGAN, training dynamics, mode collapse solutions",
                    "VAEs: latent space manipulation, reconstruction loss, disentanglement",
                    "Diffusion models: denoising process, scheduler, classifier-free guidance",
                    "Stable Diffusion: text-to-image, image-to-image, ControlNet, LoRA fine-tuning",
                    "Optimization techniques: quantization, distillation, ONNX/TensorRT",
                    "Custom fine-tuning for domain-specific applications"
                ]
            },
            {
                "module": "8",
                "title": "Audio & Video Generation",
                "duration": "10 hours",
                "topics": [
                    "Audio synthesis: WaveNet, Tacotron, HiFi-GAN, Bark, MusicGen",
                    "Voice cloning: OpenVoice, VoiceCraft, coqui-tts for Indian languages",
                    "Video generation: Deforum, Runway ML, AnimateDiff",
                    "Multimodal pipelines: lip-sync, talking avatars, sound effects",
                    "Real-time audio processing and optimization",
                    "Applications in edtech, entertainment, and content creation"
                ]
            },
            {
                "module": "9",
                "title": "Multimodal AI Systems",
                "duration": "12 hours",
                "topics": [
                    "CLIP models: embedding spaces, similarity search, zero-shot classification",
                    "Multimodal LLMs: LLaVA, GPT-4V, InstructBLIP integration",
                    "Applications: e-commerce search, edtech tutors, gaming NPCs, virtual assistants",
                    "Cross-modal understanding and generation",
                    "Edge and cloud deployment for multimodal systems",
                    "Cost optimization for Indian market applications"
                ]
            },
            {
                "module": "10",
                "title": "AI Deployment & MLOps for Generative AI",
                "duration": "10 hours",
                "topics": [
                    "MLflow and DVC: experiment tracking, model registry, versioning",
                    "Docker containerization: multi-stage builds, GPU support, security",
                    "Kubernetes orchestration: pods, services, autoscaling, GPU scheduling",
                    "FastAPI development: REST/WebSocket, streaming, rate limiting",
                    "Monitoring and alerting: Prometheus, Grafana, drift detection",
                    "Production deployment strategies for GenAI models"
                ]
            },
            {
                "module": "11",
                "title": "Capstone Projects",
                "duration": "15 hours",
                "topics": [
                    "End-to-end product development from concept to deployment",
                    "Agile development practices and team collaboration",
                    "Business impact analysis and ROI calculation",
                    "Project presentation and technical documentation",
                    "Real-world problem solving with GenAI technologies",
                    "Portfolio development and GitHub showcase"
                ]
            },
            {
                "module": "12",
                "title": "Career Preparation",
                "duration": "5 hours",
                "topics": [
                    "Portfolio building: GenAI project showcase with demos and documentation",
                    "Resume and LinkedIn optimization for AI roles in India",
                    "Technical interview preparation: coding, system design, ethics",
                    "Hackathon participation and competitive programming",
                    "Industry networking and mentorship connections",
                    "Salary negotiation and career growth strategies"
                ]
            }
        ],
        "projects": [
            {
                "title": "Personalized Children's Story Generator",
                "description": "Create an AI system that generates illustrated children's stories with Indian characters, contexts, and cultural elements using text and image generation models",
                "technologies": [
                    "GPT/Llama",
                    "Stable Diffusion",
                    "LangChain",
                    "Streamlit",
                    "MongoDB"
                ],
                "image": "https://images.pexels.com/photos/4144923/pexels-photo-4144923.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "AI Product Designer for E-commerce",
                "description": "Build a system that generates 3D product models and marketing visuals from text descriptions, optimized for Indian e-commerce platforms",
                "technologies": [
                    "Stable Diffusion",
                    "ControlNet",
                    "Three.js",
                    "FastAPI",
                    "Redis"
                ],
                "image": "https://images.pexels.com/photos/3761509/pexels-photo-3761509.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Multilingual Video Tutor",
                "description": "Develop an educational platform that creates tutorial videos with captions and voiceovers in multiple Indian languages using AI generation",
                "technologies": [
                    "Whisper",
                    "Bark",
                    "AnimateDiff",
                    "Hugging Face",
                    "PostgreSQL"
                ],
                "image": "https://images.pexels.com/photos/4145354/pexels-photo-4145354.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "AI News Anchor",
                "description": "Create realistic news video generator that produces news content with AI-generated anchors speaking in Indian accents and languages",
                "technologies": [
                    "D-ID",
                    "OpenVoice",
                    "GPT-4",
                    "FFmpeg",
                    "Docker"
                ],
                "image": "https://images.pexels.com/photos/3944454/pexels-photo-3944454.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Fashion AI Designer",
                "description": "Build an AI system that generates and recommends clothing patterns based on Indian fashion trends and cultural preferences",
                "technologies": [
                    "StyleGAN",
                    "CLIP",
                    "Fashion-MNIST",
                    "React",
                    "AWS S3"
                ],
                "image": "https://images.pexels.com/photos/3965545/pexels-photo-3965545.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            },
            {
                "title": "Cross-Modal E-commerce Search",
                "description": "Develop a search engine that accepts text and image queries to find relevant products using multimodal AI understanding",
                "technologies": [
                    "CLIP",
                    "FAISS",
                    "Elasticsearch",
                    "Vue.js",
                    "Kubernetes"
                ],
                "image": "https://images.pexels.com/photos/3746966/pexels-photo-3746966.jpeg?auto=compress&cs=tinysrgb&w=300&h=200&fit=crop"
            }
        ],
        "learningObjectives": [
            "Master the latest generative AI technologies and architectures",
            "Build production-ready GenAI applications for real-world problems",
            "Understand and implement LLMs, diffusion models, and multimodal systems",
            "Develop expertise in prompt engineering and model fine-tuning",
            "Learn to deploy and scale GenAI applications with MLOps practices",
            "Create compelling portfolio projects showcasing diverse GenAI capabilities",
            "Understand ethics and responsible AI practices for generative models",
            "Prepare for high-paying GenAI engineering roles in Bengaluru tech ecosystem"
        ],
        "prerequisites": [
            "Strong Python programming skills with OOP concepts",
            "Basic understanding of machine learning and neural networks",
            "Familiarity with data manipulation libraries (NumPy, Pandas)",
            "Linear algebra and calculus fundamentals",
            "Access to GPU-capable machine or cloud computing credits",
            "Basic understanding of APIs and web development concepts"
        ],
        "courseOutcomes": [
            "Ability to build and deploy state-of-the-art generative AI applications",
            "Expertise in fine-tuning and customizing LLMs for specific domains",
            "Skills to create multimodal AI systems combining text, image, and audio",
            "Understanding of production deployment and scaling of GenAI models",
            "Portfolio of 6+ impressive GenAI projects for job applications",
            "Preparation for GenAI Engineer, AI Researcher, and Product AI roles",
            "Network of GenAI professionals and industry mentors",
            "Confidence to lead GenAI initiatives and drive innovation in organizations"
        ],
        "toolsAndResources": {
            "frameworks": [
                "PyTorch",
                "Hugging Face Transformers",
                "LangChain",
                "LlamaIndex",
                "Diffusers",
                "Whisper"
            ],
            "platforms": [
                "Google Colab Pro",
                "Weights & Biases",
                "Hugging Face Hub",
                "Replicate",
                "Runpod"
            ],
            "databases": [
                "ChromaDB",
                "Pinecone",
                "FAISS",
                "Qdrant",
                "Weaviate"
            ],
            "deployment": [
                "FastAPI",
                "Streamlit",
                "Gradio",
                "Docker",
                "Modal"
            ],
            "assessment": [
                "Weekly hands-on labs",
                "Project-based evaluations",
                "Peer code reviews",
                "Live demo presentations"
            ]
        },
        "practicalExercises": [
            {
                "module": 1,
                "exercises": [
                    "Research GenAI use cases for Indian healthcare, e-commerce, and finance",
                    "AI ethics debate workshop on copyright and regulation",
                    "Guest lecture Q&A with local GenAI startup founder"
                ]
            },
            {
                "module": 2,
                "exercises": [
                    "Build Python pipeline scraping Indian e-commerce data with error handling",
                    "Create Dockerfile for data pipeline containerization",
                    "Implement async requests for parallel API data fetching"
                ]
            },
            {
                "module": 3,
                "exercises": [
                    "Implement 2-layer neural network from scratch using NumPy",
                    "Visualize loss landscapes for different optimizers",
                    "Derive and implement KL divergence for toy VAE/GAN"
                ]
            },
            {
                "module": 4,
                "exercises": [
                    "Preprocess multilingual Indian social media dataset for sentiment analysis",
                    "Compare traditional ML vs neural net approaches",
                    "Implement BLEU/ROUGE scoring for text generation"
                ]
            },
            {
                "module": 5,
                "exercises": [
                    "Train CNN from scratch on Indian image dataset",
                    "Implement LSTM for Indian language text generation",
                    "Build tiny transformer with attention visualization"
                ]
            },
            {
                "module": 6,
                "exercises": [
                    "Fine-tune Mistral/Llama 2 on Indian domain dataset",
                    "Build custom Q&A bot with LangChain + RAG",
                    "Implement prompt chaining for multi-step reasoning"
                ]
            },
            {
                "module": 7,
                "exercises": [
                    "Train DCGAN on Indian product image dataset",
                    "Fine-tune Stable Diffusion with LoRA on Indian art motifs",
                    "Quantize diffusion model for faster inference"
                ]
            },
            {
                "module": 8,
                "exercises": [
                    "Build podcast intro generator with voice cloning in Indian languages",
                    "Generate AI video from script using Deforum/RunwayML",
                    "Create talking avatar with lip-sync for edtech demo"
                ]
            },
            {
                "module": 9,
                "exercises": [
                    "Build cross-modal search engine for Indian e-commerce",
                    "Create virtual tutor explaining STEM with generated diagrams",
                    "Deploy multimodal chatbot for local business"
                ]
            },
            {
                "module": 10,
                "exercises": [
                    "Containerize Stable Diffusion model with Docker",
                    "Deploy scalable API on Kubernetes with FastAPI",
                    "Set up monitoring and alerts for model performance"
                ]
            }
        ],
        "assessmentCriteria": {
            "innovation": "Creative use of GenAI technologies for real-world problems",
            "technicalDepth": "Understanding of underlying generative model architectures",
            "codeQuality": "Clean, efficient, and well-documented implementation",
            "deployability": "Production-ready applications with proper MLOps practices",
            "impact": "Business value and practical applicability of solutions",
            "ethics": "Responsible AI practices and bias mitigation strategies"
        },
        "careerSupport": {
            "placementAssistance": "Resume building, portfolio review, interview preparation",
            "industryConnections": "Networking with Bengaluru GenAI ecosystem and startups",
            "mentorship": "One-on-one guidance from industry experts and alumni",
            "hackathons": "Participation in GenAI competitions and challenges",
            "continuousLearning": "Access to latest research papers and model releases"
        },
        "salaryOutcomes": {
            "genAIEngineer": "₹18-30 LPA",
            "seniorGenAIEngineer": "₹30-50 LPA",
            "genAIResearcher": "₹25-45 LPA",
            "aiProductManager": "₹35-60 LPA"
        },
        "industryPartners": [
            "Flipkart",
            "Swiggy",
            "Zomato",
            "BYJU'S",
            "Unacademy",
            "Ola",
            "Paytm",
            "PhonePe",
            "Local GenAI Startups"
        ],
        "uniqueFeatures": [
            "Focus on Indian market applications and use cases",
            "Multilingual AI development with Indian languages",
            "Local startup ecosystem integration",
            "Practical business impact analysis",
            "Ethics and regulation compliance for Indian context",
            "Cost-optimized deployment for Indian budgets"
        ]
    }
}